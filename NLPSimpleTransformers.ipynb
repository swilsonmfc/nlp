{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPSimpleTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMSOPxxYTWP59D5qW0FS9by",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e19ea13ceff344dcb77762daa8c10d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a73d25b44214622a7fefcef6fbad740",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a5cf3efab93447a882c3827b6836d83d",
              "IPY_MODEL_a9e83453f9c24183a4b70c870ae84e69"
            ]
          }
        },
        "9a73d25b44214622a7fefcef6fbad740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5cf3efab93447a882c3827b6836d83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75f872a1706c412f9befd2ff0de57cf8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a48b0784d8294424b6d75959bc6f2218"
          }
        },
        "a9e83453f9c24183a4b70c870ae84e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6bee1dab90b74e3ba9bcbe8b0589947a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 62.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b3a98e3938844c58c35f91fda683400"
          }
        },
        "75f872a1706c412f9befd2ff0de57cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a48b0784d8294424b6d75959bc6f2218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bee1dab90b74e3ba9bcbe8b0589947a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b3a98e3938844c58c35f91fda683400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05e6431085fc46dfa8a485d94b808aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_314e8d55d3b14753aa233a8c953f6c6e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b226336bc82e42e390df38f955b62f93",
              "IPY_MODEL_8945fd87f7e44143a308a2f37dd91239"
            ]
          }
        },
        "314e8d55d3b14753aa233a8c953f6c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b226336bc82e42e390df38f955b62f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9bf2bbd18ee445ba851d80eb10396379",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_323c9497a715495eab764a4b86e9b10e"
          }
        },
        "8945fd87f7e44143a308a2f37dd91239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b7c008ca47a4c5b997dcf49c3226668",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 72.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_314607089e1a4f5684471ec0fbf68252"
          }
        },
        "9bf2bbd18ee445ba851d80eb10396379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "323c9497a715495eab764a4b86e9b10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7c008ca47a4c5b997dcf49c3226668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "314607089e1a4f5684471ec0fbf68252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03214cfb85d84a6aafd88d7e5fa3a501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_509172b48be840d6acedbae71ff3600c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29db0ebed9f1499d92c8499e4f6e9e5b",
              "IPY_MODEL_7857a8a3dd07475f88daee4322438c60"
            ]
          }
        },
        "509172b48be840d6acedbae71ff3600c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29db0ebed9f1499d92c8499e4f6e9e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_044af65373334d63bdfca3fc941787dd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25ecc7c9ea0c4372b267794605e61107"
          }
        },
        "7857a8a3dd07475f88daee4322438c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca0bd5a3ae3f40f196546fff24c0a708",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 953kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18aa0b9ce99944d3b4b838e3ab2eab89"
          }
        },
        "044af65373334d63bdfca3fc941787dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25ecc7c9ea0c4372b267794605e61107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca0bd5a3ae3f40f196546fff24c0a708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18aa0b9ce99944d3b4b838e3ab2eab89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "479c2f3c43294f3e81d75226896d4868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dee90a94bc7f424f8351b13e2530d448",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50d1c9e0418a4de18c484447ca3c7a6e",
              "IPY_MODEL_3ebb7e70c6fc4b6083012c7261d43f92"
            ]
          }
        },
        "dee90a94bc7f424f8351b13e2530d448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50d1c9e0418a4de18c484447ca3c7a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0f9fbd9d9314fbd82a9d760a74fb2e7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4996,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4996,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_631fa8078bd54bfd8cb2181269c2d848"
          }
        },
        "3ebb7e70c6fc4b6083012c7261d43f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8d0069b419a46dab179dbbe00bba35b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4996/4996 [01:48&lt;00:00, 46.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee1397bacc4b42f7aebe2077cfad296e"
          }
        },
        "e0f9fbd9d9314fbd82a9d760a74fb2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "631fa8078bd54bfd8cb2181269c2d848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8d0069b419a46dab179dbbe00bba35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee1397bacc4b42f7aebe2077cfad296e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbaf4c14f5594d8e864de072be6a9dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13ad2538d1ca4c748d765c8b64800f7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b61498e991c440dda379829b650b6540",
              "IPY_MODEL_ebfd60d6860a415fab2f8e3adeffc0cf"
            ]
          }
        },
        "13ad2538d1ca4c748d765c8b64800f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b61498e991c440dda379829b650b6540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_705913b2368a4c959422a7f35c45c06a",
            "_dom_classes": [],
            "description": "Epoch 1 of 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1afab73346bb467fbc771d30803d98a9"
          }
        },
        "ebfd60d6860a415fab2f8e3adeffc0cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e58fee36b17a411ca8cec94502c1af7b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [01:45&lt;00:00, 105.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_055e4dbfd0b245cbb70cb39b24111d42"
          }
        },
        "705913b2368a4c959422a7f35c45c06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1afab73346bb467fbc771d30803d98a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e58fee36b17a411ca8cec94502c1af7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "055e4dbfd0b245cbb70cb39b24111d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b0d6e34fe084bfd949b82f5cb158027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb565298ef0e4cadaf66ae4acf43e443",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5912ebd2e6914bee91e2897dc9ee9e77",
              "IPY_MODEL_176c5b3779f14219bea7a1731a955c8f"
            ]
          }
        },
        "bb565298ef0e4cadaf66ae4acf43e443": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5912ebd2e6914bee91e2897dc9ee9e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0f69f1f2b4a4ffeabad896e8137ff8c",
            "_dom_classes": [],
            "description": "Epochs 0/1. Running Loss:    0.0101: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65fcac2d5bed48aa88398c6a588350f3"
          }
        },
        "176c5b3779f14219bea7a1731a955c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_698829c5a5604f60abd0009d8550507c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [01:45&lt;00:00,  5.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f06141c8cbba4668be9747dd96bf1748"
          }
        },
        "e0f69f1f2b4a4ffeabad896e8137ff8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65fcac2d5bed48aa88398c6a588350f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "698829c5a5604f60abd0009d8550507c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f06141c8cbba4668be9747dd96bf1748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7fe8f72783b4c36b0c474be45aa525d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a161f19321e94accb18cb575dbe194d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b3013fec7514d6db9cd232e8547bc4c",
              "IPY_MODEL_d44cd8156ee94afdbb4f78262c93cad3"
            ]
          }
        },
        "a161f19321e94accb18cb575dbe194d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b3013fec7514d6db9cd232e8547bc4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00dfdd6014db44d1bb81c3dd53e48a48",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1666,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1666,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc67b7561319483fb262ce2214dc57b8"
          }
        },
        "d44cd8156ee94afdbb4f78262c93cad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_add09c3472a04bf794be428e0eca3201",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1666/1666 [14:05&lt;00:00,  1.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_392fb10603034bd28617e04bbbba0fa9"
          }
        },
        "00dfdd6014db44d1bb81c3dd53e48a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc67b7561319483fb262ce2214dc57b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "add09c3472a04bf794be428e0eca3201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "392fb10603034bd28617e04bbbba0fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d65eb66190c4534ba2fbfd932fc95d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d9d03158120e4e8f87623fa723959830",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_832bb252f8894eef8a0c4738423c5d10",
              "IPY_MODEL_e64a64b240a14b7794814f3c41dfd599"
            ]
          }
        },
        "d9d03158120e4e8f87623fa723959830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "832bb252f8894eef8a0c4738423c5d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d465e6f6a4c4056b3f7e9d4db9381de",
            "_dom_classes": [],
            "description": "Running Evaluation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 209,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 209,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74e1fd8b8de247b38245b224be15cf3f"
          }
        },
        "e64a64b240a14b7794814f3c41dfd599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e862f45eac942b0940aac5811a4b79c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 209/209 [14:04&lt;00:00,  4.04s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9583b297ecb14503a89c8609404ccbe0"
          }
        },
        "2d465e6f6a4c4056b3f7e9d4db9381de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74e1fd8b8de247b38245b224be15cf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e862f45eac942b0940aac5811a4b79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9583b297ecb14503a89c8609404ccbe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35458c30f9e940bc85bfcc75dd892d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc77d31efc9b49d08779a088bf2a3c96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be40c80c8f764e5c8c2cf7d14fd0594c",
              "IPY_MODEL_64a5858732da4033ade1fa3db70b0d32"
            ]
          }
        },
        "bc77d31efc9b49d08779a088bf2a3c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be40c80c8f764e5c8c2cf7d14fd0594c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e328d718ad18434fb9a45b1dc9161499",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1666,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1666,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_055766cb1aa34d07a7061747babbedd9"
          }
        },
        "64a5858732da4033ade1fa3db70b0d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d748e9ed54a44df9a15cb2d698ca161a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1666/1666 [00:00&lt;00:00, 1922.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2baca7642b734ea78ee1b318a924d4ac"
          }
        },
        "e328d718ad18434fb9a45b1dc9161499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "055766cb1aa34d07a7061747babbedd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d748e9ed54a44df9a15cb2d698ca161a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2baca7642b734ea78ee1b318a924d4ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42b47e3e4da14faf98d1553c96218056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fcded74309e84da1bae74da4fc308bdf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e062f56a0e0477889cc72ea7e86a935",
              "IPY_MODEL_89209a3c733041e788dc7285b9a3e433"
            ]
          }
        },
        "fcded74309e84da1bae74da4fc308bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e062f56a0e0477889cc72ea7e86a935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2e9d7b314f6462f9b9d16a09e50be8c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 209,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 209,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f0bdb3a8dfb4607aecb71f3b72cd2d8"
          }
        },
        "89209a3c733041e788dc7285b9a3e433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec6cbf78c43c4abca199ae601d5587c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 209/209 [00:04&lt;00:00, 42.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2baeedf0d41b4142b8cf425f99f2ab2c"
          }
        },
        "e2e9d7b314f6462f9b9d16a09e50be8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f0bdb3a8dfb4607aecb71f3b72cd2d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec6cbf78c43c4abca199ae601d5587c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2baeedf0d41b4142b8cf425f99f2ab2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swilsonmfc/nlp/blob/master/NLPSimpleTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZZ21-CQrrI",
        "colab_type": "text"
      },
      "source": [
        "# Language Models - Text Classification\n",
        "![alt text](https://miro.medium.com/max/300/0*2XpE-VjhhLGkFDYg.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7mWbuckQu4m",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FE9DeQubRkx",
        "colab_type": "text"
      },
      "source": [
        "## Apex\n",
        "*  \"NVIDIA-maintained utilities to streamline mixed precision and distributed training in Pytorch\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2F2gzM0Zf96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8c141f6f-8f59-413a-8f94-77f6ae73e2dd"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 7378 (delta 9), reused 4 (delta 1), pack-reused 7353\u001b[K\n",
            "Receiving objects: 100% (7378/7378), 13.89 MiB | 28.56 MiB/s, done.\n",
            "Resolving deltas: 100% (4982/4982), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Xm9p2NbWVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a43e2da-1066-4418-acc7-ae42cd6c4f7f"
      },
      "source": [
        "cd apex"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCx45-bTbZ7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ede89c13-54f5-42a1-a1e5-2f5328a17666"
      },
      "source": [
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-jjx_4un1\n",
            "Created temporary directory: /tmp/pip-req-tracker-wu7edtdz\n",
            "Created requirements tracker '/tmp/pip-req-tracker-wu7edtdz'\n",
            "Created temporary directory: /tmp/pip-install-87r7u0aa\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-wmfa960_\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-wu7edtdz'\n",
            "    Running setup.py (path:/tmp/pip-req-build-wmfa960_/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.5.1+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-wmfa960_/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-wmfa960_/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-wmfa960_/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-wmfa960_/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-wmfa960_/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-wmfa960_/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-wmfa960_/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-wmfa960_ has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-wu7edtdz'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-kvhv2hyk\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-wmfa960_/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-wmfa960_/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-kvhv2hyk/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.5.1+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-wmfa960_/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function â€˜at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()â€™:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)â€™:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)â€™:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "         const auto& the_type = TYPE;                                             \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)â€™:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "         const auto& the_type = TYPE;                                             \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-kvhv2hyk/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-wmfa960_\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-wu7edtdz'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "socxOYRAbmjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "775e71ef-4e57-4c75-b027-8237bcbc46d5"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtLTFym6bn3Z",
        "colab_type": "text"
      },
      "source": [
        "## SimpleTransformers\n",
        "* Builds on HuggingFaces Transformers library\n",
        "* Easily construct SOTA models with relatively few lines of code\n",
        "* Support for:\n",
        "  * Sequence Classification\n",
        "  * Token Classification (NER)\n",
        "  * Question Answering\n",
        "  * Language Model Fine-Tuning\n",
        "  * Language Model Training\n",
        "  * Language Generation\n",
        "  * T5 Model\n",
        "  * Seq2Seq Tasks\n",
        "  * Multi-Modal Classification\n",
        "  * Conversational AI\n",
        "  * Text Representation Generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfZ28BlCT-DR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7dec6ce-620f-466e-d0a1-5182acbb43b7"
      },
      "source": [
        "pip install simpletransformers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simpletransformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/f3/61752c4863166c52bce48ca3112cabe62ab7e9c470afab7339f3aefe9295/simpletransformers-0.45.5-py3-none-any.whl (200kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 5.5MB/s \n",
            "\u001b[?25hCollecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ee/fedc3509145ad60fe5b418783f4a4c1b5462a4f0e8c7bbdbda52bdcda486/tokenizers-0.8.1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 20.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Collecting transformers>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.0.5)\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317kB 53.5MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.47.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/88/7b0ea5fa8192d1733dea459a9e3059afc87819cb4072c43263f2ec7ab768/tqdm-4.48.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2019.12.20)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/19/f8db9eff4b0173adf6dd2e8b0c3d8de0bfe10ec9ed63d247665980d82258/wandb-0.9.4-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->simpletransformers) (0.16.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers) (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->simpletransformers) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->simpletransformers) (2.8.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (3.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.352.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/2a/5461e1fe0026d6eab10571f81d052894328e97f15614abb6a576c65bc82d/sentry_sdk-0.16.2-py2.py3-none-any.whl (109kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 58.4MB/s \n",
            "\u001b[?25hCollecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 15.4MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/a45320cab182bf1c8656107b3d4c042e659742822fc6bff150d769a984dd/GitPython-3.1.7-py3-none-any.whl (158kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 53.8MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 16.8MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2.10)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->simpletransformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers) (49.1.0)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb->simpletransformers) (2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 11.2MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: seqeval, sacremoses, watchdog, gql, subprocess32, pathtools, graphql-core\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=59b468b749bf0323eddfe8b2f97958f9f2cd9c8f13c04626fba0feeed0e467d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=8b14364d4e4962432cf2d98695c470276f5ee9b6923f963d72fc5b2b8a942ccf\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73870 sha256=57614e70c72ae6ba25195c0cd5d028ed513ccf043a6195660eeb4834d55c4f29\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=3ce83103a06983f4991dda23c225e8587dd5d641361e7f8f51fd6f072570b9bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=cd5ba47d3bb5392df82a848debf5de6679c373b4640dbca92de24b24b6a5a3d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=7b80985a09427c0347419876ba1b10fae374277feec42fab5688868d318e2301\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=cdca2595b32dc07fdc33e834b1aaad4eb95160a17856861e655ea2e98af848db\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "Successfully built seqeval sacremoses watchdog gql subprocess32 pathtools graphql-core\n",
            "\u001b[31mERROR: transformers 3.0.2 has requirement tokenizers==0.8.1.rc1, but you'll have tokenizers 0.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, seqeval, tqdm, sacremoses, sentencepiece, transformers, tensorboardx, sentry-sdk, pathtools, watchdog, configparser, graphql-core, gql, docker-pycreds, smmap, gitdb, GitPython, subprocess32, shortuuid, wandb, simpletransformers\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed GitPython-3.1.7 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sacremoses-0.0.43 sentencepiece-0.1.91 sentry-sdk-0.16.2 seqeval-0.0.12 shortuuid-1.0.1 simpletransformers-0.45.5 smmap-3.0.4 subprocess32-3.5.4 tensorboardx-2.1 tokenizers-0.8.1 tqdm-4.48.0 transformers-3.0.2 wandb-0.9.4 watchdog-0.10.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3YwZOmpoE2c",
        "colab_type": "text"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rdSm2cEQnPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d24191f8-f783-4071-a36d-5e1daddf5150"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from simpletransformers.classification import ClassificationModel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yn1O9E2Q-1Z",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle\n",
        "![alt text](https://image.shutterstock.com/image-vector/breaking-news-background-world-global-260nw-719766118.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru7v4X1IRjUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "88a0f036-643c-4793-9d9e-d0c9db65a143"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWRzkNB3RlMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1cM5iFARlO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuclm_S7Roew",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "* News Category Dataset\n",
        "  * 41 Topic Classifications\n",
        "  * Over 200,000 articles\n",
        "  * Unbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5ACYNAoRpj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60c6849a-1741-4c54-9684-c3eca7b72132"
      },
      "source": [
        "!kaggle datasets download -d rmisra/news-category-dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading news-category-dataset.zip to /content\n",
            " 83% 21.0M/25.4M [00:01<00:00, 5.28MB/s]\n",
            "100% 25.4M/25.4M [00:01<00:00, 17.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlIZHl4IUiHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q news-category-dataset.zip"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_98WEWz5vdZ",
        "colab_type": "text"
      },
      "source": [
        "## Read\n",
        "* The file is a line based JSON document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oL5rfyDUpc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bf70054-ce64-45c4-d788-896d3aa62a89"
      },
      "source": [
        "df = pd.read_json('./News_Category_Dataset_v2.json', lines=True)\n",
        "print(f'There are {len(df)} articles')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 200853 articles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5m81XOmYwb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "19c4e72c-7205-4af4-83e7-aa4a3f79fd4c"
      },
      "source": [
        "df[[\"category\", \"headline\"]].category.value_counts().plot.bar(figsize = (12,8))\n",
        "plt.ylabel('Count')\n",
        "plt.title('Category Counts');"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTBPIYmc43wU",
        "colab_type": "text"
      },
      "source": [
        "## Subset\n",
        "* For this demo, we'll look at a small number of the most popular articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_86XQT0Q45bK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b535be51-5c90-4d30-eb35-1d2b8e43843f"
      },
      "source": [
        "CATEGORIES = ['ENTERTAINMENT', 'WELLNESS', 'POLITICS']\n",
        "df = df[df['category'].isin(CATEGORIES)].copy()\n",
        "print(f'There are {len(df)} articles after reducing')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 66624 articles after reducing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajHvMjp0a6uI",
        "colab_type": "text"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enfj2lZPu81T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c6964a7c-a4be-4f18-859e-4129b6bbae77"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category                     object\n",
              "headline                     object\n",
              "authors                      object\n",
              "link                         object\n",
              "short_description            object\n",
              "date                 datetime64[ns]\n",
              "target                        int64\n",
              "combined                     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXbefrDLu2Yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "635976e3-4a84-47b6-fb6e-4ac161efd0a3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "      <th>target</th>\n",
              "      <th>combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "      <td>0</td>\n",
              "      <td>will smith joins diplo and nicky jam for the 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>hugh grant marries for the first time at age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>the actor and his longtime girlfriend anna ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "      <td>0</td>\n",
              "      <td>hugh grant marries for the first time at age 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>jim carrey blasts 'castrato' adam schiff and d...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>the actor gives dems an ass-kicking for not fi...</td>\n",
              "      <td>2018-05-26</td>\n",
              "      <td>0</td>\n",
              "      <td>jim carrey blasts 'castrato' adam schiff and d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>julianna margulies uses donald trump poop bags...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "      <td>the \"dietland\" actress said using the bags is ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "      <td>0</td>\n",
              "      <td>julianna margulies uses donald trump poop bags...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>morgan freeman 'devastated' that sexual harass...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
              "      <td>\"it is not right to equate horrific incidents ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "      <td>0</td>\n",
              "      <td>morgan freeman 'devastated' that sexual harass...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category  ...                                           combined\n",
              "1  ENTERTAINMENT  ...  will smith joins diplo and nicky jam for the 2...\n",
              "2  ENTERTAINMENT  ...  hugh grant marries for the first time at age 5...\n",
              "3  ENTERTAINMENT  ...  jim carrey blasts 'castrato' adam schiff and d...\n",
              "4  ENTERTAINMENT  ...  julianna margulies uses donald trump poop bags...\n",
              "5  ENTERTAINMENT  ...  morgan freeman 'devastated' that sexual harass...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kySy1aoNX7V7",
        "colab_type": "text"
      },
      "source": [
        "## Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CVgdAYWbVRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "75d36f4d-f4c6-472d-f000-6c759d8b542c"
      },
      "source": [
        "grp = df.groupby('category').size()\n",
        "grp"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category\n",
              "ENTERTAINMENT    16058\n",
              "POLITICS         32739\n",
              "WELLNESS         17827\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfuvDdPMVF0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "df['target'] = encoder.fit_transform(df.category)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORIrYPlaYC9V",
        "colab_type": "text"
      },
      "source": [
        "## Headlines\n",
        "* We'll do very minimal feature engineering for a baseline\n",
        "* Merge headline and the short description together \n",
        "* There are two headline categories that should be merged:\n",
        "  * WORLDPOST\n",
        "  * THE WORLDPOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrFuHLCvYBAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['headline']          = df.headline.str.lower()\n",
        "df['short_description'] = df.short_description.str.lower()\n",
        "df['combined']          = df['headline'] + ' ' + df['short_description']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nieTBgpFZa8B",
        "colab_type": "text"
      },
      "source": [
        "# NLP Task\n",
        "* Text Classification\n",
        "* Given the headline / description identify the category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkjtZJS8agrx",
        "colab_type": "text"
      },
      "source": [
        "## Context-Free vs Context-Aware\n",
        "* In prior notebooks we looked at topic modeling and embeddings\n",
        "* Topics and embeddings are context free:\n",
        "  * Words with multiple meanings get the same embedding values\n",
        "  * For example:\n",
        "    * The **bank** was closed for a holiday.\n",
        "    * The people sat on the river **bank**. \n",
        "* Language models are context aware:\n",
        "  * Position in the sentence and neighboring words affect the word.\n",
        "  * Context aware models can derive different meaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92TF1h7BcLlK",
        "colab_type": "text"
      },
      "source": [
        "## Classification Options\n",
        "* Vector\n",
        "  * Bag of Words \n",
        "  * TF-IDF \n",
        "  * Topic Model\n",
        "  * Embedding\n",
        "* Common Classifications\n",
        "  * Naive Bayes\n",
        "  * Bagging / Boosting\n",
        "  * MLP\n",
        "* Sequence Based Classification\n",
        "  * LSTM / GRU\n",
        "  * CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOgln3M8dbbA",
        "colab_type": "text"
      },
      "source": [
        "## Challenges\n",
        "* You need many examples to train language models\n",
        "  * Expensive\n",
        "  * Time consuming\n",
        "* Existing word vectors (word2vec) produce a 1-1 mapping between the token and the vector\n",
        "* LSTMs have limits in number of tokens\n",
        "  * Exploding / Vanishing gradients\n",
        "  * You may need to add gradient clipping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iHV9o0rlPFl",
        "colab_type": "text"
      },
      "source": [
        "# Seq2Seq\n",
        "* While classification asks for a binary or multi-class output, we often need a sequence of labels emitted\n",
        "* For these NLP tasks a Seq2Seq approach is used\n",
        "  * Language Translation \n",
        "  * Text / Speech generation\n",
        "  * Summarization\n",
        "  * Relation / Named Entity Classification or Extraction\n",
        "  * Chatbots\n",
        "* In Seq2Seq we use an encoder and decoder\n",
        "* Encoder\n",
        "  * Typically is an LSTM or GRU\n",
        "  * The encoder sees the original text token by token\n",
        "  * It outputs an encoded vector \n",
        "* Decoder\n",
        "  * Like the encoder, it uses an LSTM or GRU\n",
        "  * Receives\n",
        "    * An encoded vector from the Encoder\n",
        "    * Start Token  \n",
        "  * Continues sequentially until it emits a stop token\n",
        "* Seq2Seq Intuition\n",
        "  * The encoder takes our \"understanding\" and captures that in an embedding\n",
        "  * The decoder emits a series of tokens (ending with a stop word)\n",
        "  * These tokens represent a soft-max (over the vocabulary)\n",
        "\n",
        "\n",
        "![alt text](https://www.kdnuggets.com/images/transformer-fig1-encoder-decoder-700.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfP87WxYjkjb",
        "colab_type": "text"
      },
      "source": [
        "## Attention Is All You Need \n",
        "* The challenge is how to get the best \"embedding\" in a Seq2Seq architecture\n",
        "* The \"input\" tokens themselves are extremely helpful\n",
        "  * Hidden states of the RNN in the encoder\n",
        "  * Pass them, along with the encoder vector\n",
        "* Influential paper published June 2017\n",
        "* https://arxiv.org/abs/1706.03762\n",
        "\n",
        "![alt text](https://jalammar.github.io/images/attention_sentence.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VwwNW9-jIWG",
        "colab_type": "text"
      },
      "source": [
        "## Transformer Architecture\n",
        "\n",
        "![alt text](http://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIkD9beVhVUX",
        "colab_type": "text"
      },
      "source": [
        "## Transfer Learning\n",
        "* Builds on the advancements in the Transformer \n",
        "* Improvements in 2018\n",
        "  * [Allen NLP Elmo](https://allennlp.org/elmo)\n",
        "    * Embeddings from Language Models\n",
        "  * [OpenAI Open-GPT](https://openai.com/blog/language-unsupervised/)\n",
        "    * Generative Pretrained Transformer\n",
        "  * [Google BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)\n",
        "    * Bidirectional Encoder Representations from Transformers\n",
        "  * [FastAI](https://docs.fast.ai/text.html)\n",
        "    * Universal Language Model - FIne Tuning\n",
        "* Image processing productivity for NLP tasks\n",
        "  * Reusable architecture\n",
        "  * Reusable layer weights\n",
        "* Massive training time reduction\n",
        "  * From hundreds of hours and many GPU\n",
        "  * 15-30 minutes one GPU\n",
        "* Fine-Tuning language models\n",
        "  * Small number of epochs (often 2-3)\n",
        "* Magnitudes less data\n",
        "  * We can focus on the task at hand\n",
        "  * Don't need to \"learn\" language features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6_LoLy_mdIT",
        "colab_type": "text"
      },
      "source": [
        "# Approach\n",
        "* Use the SimpleTransformers high productivity / low code interface to a language modeling classification task\n",
        "* Reuse the BERT trained language model\n",
        "* BERT builds on the Transformer architecture\n",
        "* Apply the BERT tokenization\n",
        "* Use the language model to classify our category given the text headline + description\n",
        "* Evaluate our results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "729NcaFmaQfk",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "* Standard train - test split\n",
        "* Tokenizing the text for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l2-bxZadJwv",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kdIKMnlYic-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[['combined', 'target']].copy()\n",
        "X = X.sample(frac=0.1)\n",
        "y = X['target']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2YuMEEdLH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=987)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2v8I0j0deMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a87f376-6f47-4c6e-fbaf-ecff54acdf67"
      },
      "source": [
        "print(f'Train {X_train.shape}, {y_train.shape}')\n",
        "print(f'Test  {X_test.shape}, {y_test.shape}')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train (4996, 2), (4996,)\n",
            "Test  (1666, 2), (1666,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYIn9h2ueBik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "389f9710-ef7a-473c-fdc7-c563dfdbce1a"
      },
      "source": [
        "print(f'Average Description Length {np.mean(X_train.combined.str.len()):.2f}')\n",
        "print(f'Median  Description Length {np.median(X_train.combined.str.len()):.2f}')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Description Length 171.24\n",
            "Median  Description Length 164.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGcIvV_SrvmJ",
        "colab_type": "text"
      },
      "source": [
        "## BERT Encoding\n",
        "* BERT uses a special encoding format for words in sentences\n",
        "* Can take in one or two sentences\n",
        "* [CLS] Start of the classficiation task\n",
        "* [SEP] Separates sentence 1 from 2 and always provided\n",
        "* BERT has word embeddings for 30,000 words (much smaller than an English vocabulary)\n",
        "* BERT avoids using unknown tokens\n",
        "* BERT uses a word piece model\n",
        "* BERT will break out parts of the word into tokens:\n",
        "  * \"embeddings\" is not in the vocab\n",
        "  * Rather than [UNK] it's broken up piece-wise\n",
        "  * Parts of words are tagged with ##\n",
        "  * em, ##bed, ##ding ##s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYL0SgkjWikS",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbS9DMmkWkiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "e19ea13ceff344dcb77762daa8c10d7a",
            "9a73d25b44214622a7fefcef6fbad740",
            "a5cf3efab93447a882c3827b6836d83d",
            "a9e83453f9c24183a4b70c870ae84e69",
            "75f872a1706c412f9befd2ff0de57cf8",
            "a48b0784d8294424b6d75959bc6f2218",
            "6bee1dab90b74e3ba9bcbe8b0589947a",
            "0b3a98e3938844c58c35f91fda683400",
            "05e6431085fc46dfa8a485d94b808aa1",
            "314e8d55d3b14753aa233a8c953f6c6e",
            "b226336bc82e42e390df38f955b62f93",
            "8945fd87f7e44143a308a2f37dd91239",
            "9bf2bbd18ee445ba851d80eb10396379",
            "323c9497a715495eab764a4b86e9b10e",
            "7b7c008ca47a4c5b997dcf49c3226668",
            "314607089e1a4f5684471ec0fbf68252",
            "03214cfb85d84a6aafd88d7e5fa3a501",
            "509172b48be840d6acedbae71ff3600c",
            "29db0ebed9f1499d92c8499e4f6e9e5b",
            "7857a8a3dd07475f88daee4322438c60",
            "044af65373334d63bdfca3fc941787dd",
            "25ecc7c9ea0c4372b267794605e61107",
            "ca0bd5a3ae3f40f196546fff24c0a708",
            "18aa0b9ce99944d3b4b838e3ab2eab89"
          ]
        },
        "outputId": "15b9524d-f813-4337-f5a9-29abfa4674a7"
      },
      "source": [
        "model = ClassificationModel('bert', 'bert-base-uncased', num_labels=3,\n",
        "                            args={'reprocess_input_data': True, 'overwrite_output_dir': True})"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e19ea13ceff344dcb77762daa8c10d7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05e6431085fc46dfa8a485d94b808aa1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03214cfb85d84a6aafd88d7e5fa3a501",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xowTsZRpW2XO",
        "colab_type": "text"
      },
      "source": [
        "# Train\n",
        "* SimpleTransformers will default to a 2 column scheme\n",
        "  * First column is the text to encode\n",
        "  * Second column is the target library\n",
        "* The encoding will be specific to the transformer loaded into the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MrO9k2LYe2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "41f10984-39a2-4519-d233-3b3233327d38"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15695</th>\n",
              "      <td>when will the economy start caring about home-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120801</th>\n",
              "      <td>\"amazing grace\" garcia and her legacy among te...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108099</th>\n",
              "      <td>new york police study reveals 'stark racial bi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200103</th>\n",
              "      <td>what to do at the gym: your fitness etiquette ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166760</th>\n",
              "      <td>stress less: 30 things you decided are not wor...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154354</th>\n",
              "      <td>'the hobbit 2' poster: 'desolation of smaug' i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90173</th>\n",
              "      <td>kylie jenner &amp; tyga get close at the monaco gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157672</th>\n",
              "      <td>signs of stress (video) you are not alone. eig...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34208</th>\n",
              "      <td>regis philbin says 'very offended' kelly ripa ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25665</th>\n",
              "      <td>jeff sessions reportedly failed to list russia...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4996 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 combined  target\n",
              "15695   when will the economy start caring about home-...       1\n",
              "120801  \"amazing grace\" garcia and her legacy among te...       1\n",
              "108099  new york police study reveals 'stark racial bi...       1\n",
              "200103  what to do at the gym: your fitness etiquette ...       2\n",
              "166760  stress less: 30 things you decided are not wor...       2\n",
              "...                                                   ...     ...\n",
              "154354  'the hobbit 2' poster: 'desolation of smaug' i...       0\n",
              "90173   kylie jenner & tyga get close at the monaco gr...       0\n",
              "157672  signs of stress (video) you are not alone. eig...       2\n",
              "34208   regis philbin says 'very offended' kelly ripa ...       0\n",
              "25665   jeff sessions reportedly failed to list russia...       1\n",
              "\n",
              "[4996 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzpTVCj-W35M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "479c2f3c43294f3e81d75226896d4868",
            "dee90a94bc7f424f8351b13e2530d448",
            "50d1c9e0418a4de18c484447ca3c7a6e",
            "3ebb7e70c6fc4b6083012c7261d43f92",
            "e0f9fbd9d9314fbd82a9d760a74fb2e7",
            "631fa8078bd54bfd8cb2181269c2d848",
            "b8d0069b419a46dab179dbbe00bba35b",
            "ee1397bacc4b42f7aebe2077cfad296e",
            "bbaf4c14f5594d8e864de072be6a9dec",
            "13ad2538d1ca4c748d765c8b64800f7d",
            "b61498e991c440dda379829b650b6540",
            "ebfd60d6860a415fab2f8e3adeffc0cf",
            "705913b2368a4c959422a7f35c45c06a",
            "1afab73346bb467fbc771d30803d98a9",
            "e58fee36b17a411ca8cec94502c1af7b",
            "055e4dbfd0b245cbb70cb39b24111d42",
            "2b0d6e34fe084bfd949b82f5cb158027",
            "bb565298ef0e4cadaf66ae4acf43e443",
            "5912ebd2e6914bee91e2897dc9ee9e77",
            "176c5b3779f14219bea7a1731a955c8f",
            "e0f69f1f2b4a4ffeabad896e8137ff8c",
            "65fcac2d5bed48aa88398c6a588350f3",
            "698829c5a5604f60abd0009d8550507c",
            "f06141c8cbba4668be9747dd96bf1748"
          ]
        },
        "outputId": "10f1d684-c474-49ad-af93-ad5caf84d964"
      },
      "source": [
        "model.train_model(X_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:278: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "479c2f3c43294f3e81d75226896d4868",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4996.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbaf4c14f5594d8e864de072be6a9dec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='iâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b0d6e34fe084bfd949b82f5cb158027",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 1', max=625.0, style=ProgressStyle(desâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpKoIzEPku4v",
        "colab_type": "text"
      },
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppwDRP4clXrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "f7fe8f72783b4c36b0c474be45aa525d",
            "a161f19321e94accb18cb575dbe194d2",
            "3b3013fec7514d6db9cd232e8547bc4c",
            "d44cd8156ee94afdbb4f78262c93cad3",
            "00dfdd6014db44d1bb81c3dd53e48a48",
            "bc67b7561319483fb262ce2214dc57b8",
            "add09c3472a04bf794be428e0eca3201",
            "392fb10603034bd28617e04bbbba0fa9",
            "7d65eb66190c4534ba2fbfd932fc95d5",
            "d9d03158120e4e8f87623fa723959830",
            "832bb252f8894eef8a0c4738423c5d10",
            "e64a64b240a14b7794814f3c41dfd599",
            "2d465e6f6a4c4056b3f7e9d4db9381de",
            "74e1fd8b8de247b38245b224be15cf3f",
            "4e862f45eac942b0940aac5811a4b79c",
            "9583b297ecb14503a89c8609404ccbe0"
          ]
        },
        "outputId": "15666d8d-7962-48ac-8ac8-ae93834c5bee"
      },
      "source": [
        "result, model_outputs, wrong_predictions = model.eval_model(X_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:751: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7fe8f72783b4c36b0c474be45aa525d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1666.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d65eb66190c4534ba2fbfd932fc95d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=209.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSdfIBhVe5Qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8671322-9ece-487b-89ea-5dfbd25daafd"
      },
      "source": [
        "result"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.20359978386374752, 'mcc': 0.9248603448734802}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI2qiyo6e9Xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "30115714-96f3-49b4-85d1-651b43016a60"
      },
      "source": [
        "model_outputs"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.34375   ,  3.7265625 , -2.3496094 ],\n",
              "       [-1.7480469 ,  4.0625    , -3.4726562 ],\n",
              "       [-2.2773438 ,  4.0976562 , -2.8886719 ],\n",
              "       ...,\n",
              "       [-1.8154297 ,  3.7597656 , -3.0703125 ],\n",
              "       [ 0.8173828 ,  1.5527344 , -2.2832031 ],\n",
              "       [-0.56347656,  2.3320312 , -1.9833984 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etfRg7D4Lx06",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo1lhmkBhHyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9136a5f6-1175-45be-9aac-818226b54fbc"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4608</th>\n",
              "      <td>bomb-sniffing army dogs got terrible treatment...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54193</th>\n",
              "      <td>trump praises saddam hussein again â€” this time...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81841</th>\n",
              "      <td>hillary clinton compares gop's 'extreme views'...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>gal gadot beautifully thanks wonder woman on s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51782</th>\n",
              "      <td>maggie gyllenhaal just starred in three movies...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110056</th>\n",
              "      <td>yup, chelsea handler posted this photo on twit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143202</th>\n",
              "      <td>'the secret life of walter mitty' review: earn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78404</th>\n",
              "      <td>cruz: letting muslim syrian refugees into the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115869</th>\n",
              "      <td>'i'm having an abortion this weekend'</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17630</th>\n",
              "      <td>'a rising tide lifts all boats,' but the boatl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1666 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 combined  target\n",
              "4608    bomb-sniffing army dogs got terrible treatment...       1\n",
              "54193   trump praises saddam hussein again â€” this time...       1\n",
              "81841   hillary clinton compares gop's 'extreme views'...       1\n",
              "3416    gal gadot beautifully thanks wonder woman on s...       0\n",
              "51782   maggie gyllenhaal just starred in three movies...       0\n",
              "...                                                   ...     ...\n",
              "110056  yup, chelsea handler posted this photo on twit...       0\n",
              "143202  'the secret life of walter mitty' review: earn...       0\n",
              "78404   cruz: letting muslim syrian refugees into the ...       1\n",
              "115869             'i'm having an abortion this weekend'        1\n",
              "17630   'a rising tide lifts all boats,' but the boatl...       1\n",
              "\n",
              "[1666 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVHZbQXTg6fC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "35458c30f9e940bc85bfcc75dd892d56",
            "bc77d31efc9b49d08779a088bf2a3c96",
            "be40c80c8f764e5c8c2cf7d14fd0594c",
            "64a5858732da4033ade1fa3db70b0d32",
            "e328d718ad18434fb9a45b1dc9161499",
            "055766cb1aa34d07a7061747babbedd9",
            "d748e9ed54a44df9a15cb2d698ca161a",
            "2baca7642b734ea78ee1b318a924d4ac",
            "42b47e3e4da14faf98d1553c96218056",
            "fcded74309e84da1bae74da4fc308bdf",
            "5e062f56a0e0477889cc72ea7e86a935",
            "89209a3c733041e788dc7285b9a3e433",
            "e2e9d7b314f6462f9b9d16a09e50be8c",
            "6f0bdb3a8dfb4607aecb71f3b72cd2d8",
            "ec6cbf78c43c4abca199ae601d5587c4",
            "2baeedf0d41b4142b8cf425f99f2ab2c"
          ]
        },
        "outputId": "19187fd1-d9cf-486b-80c1-15d2f637fc6a"
      },
      "source": [
        "pred = model.predict(X_test['combined'].tolist())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35458c30f9e940bc85bfcc75dd892d56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1666.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42b47e3e4da14faf98d1553c96218056",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=209.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdvZBuwIiQQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8588169c-65f5-4413-8e81-0dcfca27c663"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4608      1\n",
              "54193     1\n",
              "81841     1\n",
              "3416      0\n",
              "51782     0\n",
              "         ..\n",
              "110056    0\n",
              "143202    0\n",
              "78404     1\n",
              "115869    1\n",
              "17630     1\n",
              "Name: target, Length: 1666, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoRchdmMhfGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c4ff0dd-fd1b-495b-fda2-560681654ae7"
      },
      "source": [
        "pred_classes = pred[0]\n",
        "pred_classes"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxTKiIt3hZ9V",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwADYUQgLw17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2c7a7a86-a2f8-42c2-d9f1-8d7729ed9484"
      },
      "source": [
        "encoded_classes    = CATEGORIES\n",
        "predicted_category = [encoded_classes[x] for x in pred_classes]\n",
        "true_category      = [encoded_classes[x] for x in y_test]\n",
        "\n",
        "result_df = pd.DataFrame({'description' : X_test['combined'],\n",
        "                          'true_category' : true_category, \n",
        "                          'predicted_category' : predicted_category})\n",
        "result_df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>true_category</th>\n",
              "      <th>predicted_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4608</th>\n",
              "      <td>bomb-sniffing army dogs got terrible treatment...</td>\n",
              "      <td>WELLNESS</td>\n",
              "      <td>WELLNESS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54193</th>\n",
              "      <td>trump praises saddam hussein again â€” this time...</td>\n",
              "      <td>WELLNESS</td>\n",
              "      <td>WELLNESS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81841</th>\n",
              "      <td>hillary clinton compares gop's 'extreme views'...</td>\n",
              "      <td>WELLNESS</td>\n",
              "      <td>WELLNESS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>gal gadot beautifully thanks wonder woman on s...</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51782</th>\n",
              "      <td>maggie gyllenhaal just starred in three movies...</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             description  ... predicted_category\n",
              "4608   bomb-sniffing army dogs got terrible treatment...  ...           WELLNESS\n",
              "54193  trump praises saddam hussein again â€” this time...  ...           WELLNESS\n",
              "81841  hillary clinton compares gop's 'extreme views'...  ...           WELLNESS\n",
              "3416   gal gadot beautifully thanks wonder woman on s...  ...      ENTERTAINMENT\n",
              "51782  maggie gyllenhaal just starred in three movies...  ...      ENTERTAINMENT\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyzs-bMQiuDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_classification_report(test, pred, target_names):\n",
        "  report = classification_report(test, pred, target_names=target_names)\n",
        "  print(report)  \n",
        "\n",
        "def plot_confusion(test, pred, labels):\n",
        "  cm = confusion_matrix(test, pred)\n",
        "  df = pd.DataFrame(cm, labels, labels)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  sns.heatmap(df, annot=True, fmt='d', cmap='BuGn')\n",
        "  plt.xlabel('Prediction')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.show()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcMiFZQYkDrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "b2f51cc2-2279-4a3b-851f-1c1ab7ea70ae"
      },
      "source": [
        "plot_confusion(true_category, \n",
        "               predicted_category, \n",
        "               list(encoded_classes))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4PX7HrAkVAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "19f50904-dde2-419a-f7f8-0f3811f78fd8"
      },
      "source": [
        "print_classification_report(true_category, \n",
        "               predicted_category, \n",
        "               list(encoded_classes))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "ENTERTAINMENT       0.91      0.94      0.92       408\n",
            "     WELLNESS       0.97      0.96      0.97       474\n",
            "     POLITICS       0.96      0.96      0.96       784\n",
            "\n",
            "     accuracy                           0.95      1666\n",
            "    macro avg       0.95      0.95      0.95      1666\n",
            " weighted avg       0.95      0.95      0.95      1666\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qiQtrKRsTHb",
        "colab_type": "text"
      },
      "source": [
        "# Closing\n",
        "* Consider layering:\n",
        "  * SimpleTransformers \n",
        "    * Like FastAI for PyTorch and Keras for TF\n",
        "    * Great for baselining / POC\n",
        "    * Downside, installation isn't trivial with Apex (pip)\n",
        "  * Transformers \n",
        "    * HuggingFace (https://github.com/huggingface)\n",
        "    * Build your fine-tuning model\n",
        "    * Manipulate the tokenization & layering of archtecture\n",
        "* Jay Alammar \n",
        "  * http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
        "  * http://jalammar.github.io/illustrated-bert/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLgYQcFmvFkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}