{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPNamedEntityRecognition",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHL04GbZnT72Yi6ectSeya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddf1a902b61747edadfd4937e3377db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2385a043f3940c097fe47450fae304c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47a6deef8c484467b2c955c63b13a61b",
              "IPY_MODEL_f14f70d97b0a46fabd99bf08f822e671"
            ]
          }
        },
        "f2385a043f3940c097fe47450fae304c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47a6deef8c484467b2c955c63b13a61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f645002f57db4cc8bbc107e27f076375",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_324ecea551724b499b3a938002bbd24b"
          }
        },
        "f14f70d97b0a46fabd99bf08f822e671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6af8758c3645452f9ac5c2c4bdbc7069",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 735kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49a2e95e75884fd1a8889bab8132ad0c"
          }
        },
        "f645002f57db4cc8bbc107e27f076375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "324ecea551724b499b3a938002bbd24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6af8758c3645452f9ac5c2c4bdbc7069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49a2e95e75884fd1a8889bab8132ad0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "133c8327261444f7be7040a5cccdf4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3fb06abfa7e24c83a9b89a64d48c798c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be72c06a01dd48508dbc75b7588808d3",
              "IPY_MODEL_d31de5c49808491298d12b77725e4c8b"
            ]
          }
        },
        "3fb06abfa7e24c83a9b89a64d48c798c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be72c06a01dd48508dbc75b7588808d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_801187a9b80a4b538135149009a8e500",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36a550ee86fb4ab1a6a2a3c75a2b3537"
          }
        },
        "d31de5c49808491298d12b77725e4c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eadd153182ad4d51bbc39ebb22f39096",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 8.65kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e316e572c364ab59e80475fc43d028a"
          }
        },
        "801187a9b80a4b538135149009a8e500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36a550ee86fb4ab1a6a2a3c75a2b3537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eadd153182ad4d51bbc39ebb22f39096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e316e572c364ab59e80475fc43d028a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f260f0941afd4203ad15a0cdd84329c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2629a20ec2004ffa8cd87979aff4b9f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1bfd6f8ee5164879a16eb3e2c01a3772",
              "IPY_MODEL_a634700ae350496483eaadfd62458072"
            ]
          }
        },
        "2629a20ec2004ffa8cd87979aff4b9f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bfd6f8ee5164879a16eb3e2c01a3772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2aa46d5b963e40c1afa2516a570debe0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fec273a76fd84c75992a4afcb0f3b6f8"
          }
        },
        "a634700ae350496483eaadfd62458072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f6c3e5d4cd14ae5961eaa28d440c662",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 47.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb4c132e6119424db5dbedc0e84a6935"
          }
        },
        "2aa46d5b963e40c1afa2516a570debe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fec273a76fd84c75992a4afcb0f3b6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f6c3e5d4cd14ae5961eaa28d440c662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb4c132e6119424db5dbedc0e84a6935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swilsonmfc/nlp/blob/master/NLPNamedEntityRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyip83LTH1lw",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition\n",
        "![alt text](https://cdn.britannica.com/55/188355-050-D5E49258/Salvatore-Corsitto-The-Godfather-Marlon-Brando-Francis.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmF_3XuEILMa",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvYfqhwjIbQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "4170d798-fbcc-4223-e643-199276a65bad"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 8.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 5.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=a19c7f5d8a62f106498a132068da0060d67571907c370293b3e5c2460c77641f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CatZ31rMIffz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "0765ed4c-5044-4bfa-e0c0-368196a8cbd0"
      },
      "source": [
        "pip install wget"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=364235bcf50439ddb45f10da6a34eb317a627d9da5b153ff211e10c6ea0c8182\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QqjyWndH9f_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cb23497d-b77a-46fc-e4df-9a8871af27b7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import wget\n",
        "import csv\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import pprint as pp\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForTokenClassification\n",
        "from transformers import AdamW\n",
        "from transformers import BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import RandomSampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7BwC4tdVnJg",
        "colab_type": "text"
      },
      "source": [
        "# BERT\n",
        "* Fine-tuning BERT for token classification\n",
        "* BERT base & uncased\n",
        "\n",
        "![alt text](http://jalammar.github.io/images/bert-base-bert-large-encoders.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTz9ORQ7VoyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ddf1a902b61747edadfd4937e3377db4",
            "f2385a043f3940c097fe47450fae304c",
            "47a6deef8c484467b2c955c63b13a61b",
            "f14f70d97b0a46fabd99bf08f822e671",
            "f645002f57db4cc8bbc107e27f076375",
            "324ecea551724b499b3a938002bbd24b",
            "6af8758c3645452f9ac5c2c4bdbc7069",
            "49a2e95e75884fd1a8889bab8132ad0c"
          ]
        },
        "outputId": "c7ebdf2a-fc4d-4460-cd71-14c992a1a6fe"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddf1a902b61747edadfd4937e3377db4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2cxwuZ7IRnv",
        "colab_type": "text"
      },
      "source": [
        "# GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Go60s9KIOAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a816a56b-6f83-41d2-a8de-c7774be3008c"
      },
      "source": [
        "if torch.cuda.is_available():       \n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s).')\n",
        "    print(f'GPU Type: {torch.cuda.get_device_name(0)}')\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print('No GPU available, using CPU.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s).\n",
            "GPU Type: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDw_lzG9IvBr",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "* Using the MIT Movie Task\n",
        "* Formatted in BIO (or IOB) Format\n",
        "* BIO = Beginning, Inside, Outside\n",
        "\n",
        "TAG | EXAMPLE\n",
        "--- | ---\n",
        "ACTOR|Matt Damon\n",
        "YEAR|1980s\n",
        "TITLE|Pulp Fiction\n",
        "GENRE|science fiction\n",
        "DIRECTOR|George Lucas\n",
        "SONG|Aerosmith\n",
        "PLOT|Flying cars\n",
        "REVIEW|must see\n",
        "CHARACTER|Queen Elizabeth\n",
        "RATING|PG-13\n",
        "RATINGS_AVERAGE|best rated\n",
        "TRAILER|preview\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6pcYXGFIvwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a666ce57-add2-41c0-d19f-39f5ba5c48a2"
      },
      "source": [
        "wget.download('https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio', './engtrain.bio')\n",
        "wget.download('https://groups.csail.mit.edu/sls/downloads/movie/engtest.bio',  './engtest.bio')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./engtest.bio'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHRBs7o4JI8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3954c027-8c0f-4ad2-8b8f-9f19c784e115"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "engtest.bio  engtrain.bio  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku0ULMQIJgu0",
        "colab_type": "text"
      },
      "source": [
        "# Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbyUYBCyJM6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_bio(file):\n",
        "  \"\"\"\n",
        "  We read along, pushing tokens & any labels onto a local list \n",
        "  When we hit an empty line, the sentence is constructed\n",
        "  Append it to the sentences & labels lists, reset tokens and continue\n",
        "  \"\"\"\n",
        "  sentences = []\n",
        "  labels = []\n",
        "\n",
        "  # Lists to store the current iteration / sentence\n",
        "  tokens = []\n",
        "  token_labels = []\n",
        "\n",
        "  with open(file, newline = '') as lines:                                                                                          \n",
        "      reader = csv.reader(lines, delimiter='\\t')\n",
        "      for line in reader:\n",
        "          if line == []:\n",
        "              # Store full sentence\n",
        "              sentences.append(tokens)\n",
        "              labels.append(token_labels)           \n",
        "      \n",
        "              # Start new\n",
        "              tokens = []\n",
        "              token_labels = []        \n",
        "\n",
        "          else: \n",
        "              # Append to the sentence buffer\n",
        "              tokens.append(line[1])\n",
        "              token_labels.append(line[0])\n",
        "\n",
        "  return sentences, labels"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMkjaWnQqxvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences, labels = read_bio('./engtrain.bio')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13AFAlSxQuQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "43ba2b5a-2e25-4fcb-f8e6-dd89ee6214d8"
      },
      "source": [
        "for i in range(5):\n",
        "  print(f'{\" \".join(sentences[i])}')\n",
        "  print(f'{\" \".join(labels[i])}')\n",
        "  print('\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what movies star bruce willis\n",
            "O O O B-ACTOR I-ACTOR\n",
            "\n",
            "\n",
            "show me films with drew barrymore from the 1980s\n",
            "O O O O B-ACTOR I-ACTOR O O B-YEAR\n",
            "\n",
            "\n",
            "what movies starred both al pacino and robert deniro\n",
            "O O O O B-ACTOR I-ACTOR O B-ACTOR I-ACTOR\n",
            "\n",
            "\n",
            "find me all of the movies that starred harold ramis and bill murray\n",
            "O O O O O O O O B-ACTOR I-ACTOR O B-ACTOR I-ACTOR\n",
            "\n",
            "\n",
            "find me a movie with a quote about baseball in it\n",
            "O O O O O O O O O O O\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZI_RCK6Vv-R",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQLpaHEHqBjI",
        "colab_type": "text"
      },
      "source": [
        "## Label to Id Index\n",
        "* Create a mapping from our BIO labels to integer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVYYiASGORZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_label_index(labels):\n",
        "  \"\"\"\n",
        "  Given a list of sentence labels (list of lists)\n",
        "  Construct a dictionary mapping each label to a unique integer\n",
        "  \"\"\"\n",
        "  unique  = set([label for sentence_labels in labels for label in sentence_labels])\n",
        "  mapping = {k: v for v, k in enumerate(unique)} \n",
        "  return mapping"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPrQCA715Z6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label2id = generate_label_index(labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrZ18uHS9-er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "a234579c-7db9-45c6-8f78-01622dd7955e"
      },
      "source": [
        "pp.pprint(label2id)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-ACTOR': 13,\n",
            " 'B-CHARACTER': 2,\n",
            " 'B-DIRECTOR': 3,\n",
            " 'B-GENRE': 1,\n",
            " 'B-PLOT': 22,\n",
            " 'B-RATING': 5,\n",
            " 'B-RATINGS_AVERAGE': 11,\n",
            " 'B-REVIEW': 19,\n",
            " 'B-SONG': 24,\n",
            " 'B-TITLE': 12,\n",
            " 'B-TRAILER': 20,\n",
            " 'B-YEAR': 17,\n",
            " 'I-ACTOR': 15,\n",
            " 'I-CHARACTER': 6,\n",
            " 'I-DIRECTOR': 23,\n",
            " 'I-GENRE': 7,\n",
            " 'I-PLOT': 8,\n",
            " 'I-RATING': 4,\n",
            " 'I-RATINGS_AVERAGE': 9,\n",
            " 'I-REVIEW': 18,\n",
            " 'I-SONG': 21,\n",
            " 'I-TITLE': 10,\n",
            " 'I-TRAILER': 16,\n",
            " 'I-YEAR': 14,\n",
            " 'O': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpcNE8RpqGhS",
        "colab_type": "text"
      },
      "source": [
        "## Apply BERT Tokens\n",
        "* Encode the data for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZiVAVk8QQbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentences):\n",
        "  \"\"\"\n",
        "  Join sentence from token back into string for BERT\n",
        "  Take in the list of sentences and use the BERT encode_plus to:\n",
        "  * Add [CLS] to the start\n",
        "  * Add [SEP] to the end\n",
        "  * Add [PAD] to max length\n",
        "  * Map any tokens to an identifier\n",
        "  * Unknown tokens split using double-hash\n",
        "  * Return our attention mask and pytorch tensors\n",
        "  \"\"\"\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  for sentence in sentences:\n",
        "      text = ' '.join(sentence)\n",
        "      encoded_dict = tokenizer.encode_plus(text, \n",
        "                                           add_special_tokens = True, \n",
        "                                           truncation = True,\n",
        "                                           max_length = 50,  \n",
        "                                           pad_to_max_length = True,\n",
        "                                           return_attention_mask = True,   \n",
        "                                           return_tensors = 'pt')\n",
        "      \n",
        "      # Append and process next sentence\n",
        "      input_ids.append(encoded_dict['input_ids'][0])\n",
        "      attention_masks.append(encoded_dict['attention_mask'][0])\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEutVYvX5Yju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids, attention_masks = tokenize(sentences)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqQJyU8K-KAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cad8c085-662e-488d-ab8d-1c9608136c98"
      },
      "source": [
        "pp.pprint(input_ids[2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  2054,  5691,  5652,  2119,  2632, 14397,  5740,  1998,  2728,\n",
            "         7939,  9711,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be3cv3s--OQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "75591146-2a2e-48a9-caca-c8b191c5a1aa"
      },
      "source": [
        "pp.pprint(attention_masks[2])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stUwN-jeqLUN",
        "colab_type": "text"
      },
      "source": [
        "## Apply Custom Token\n",
        "* Interject our custom NER tokens into the BERT encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xepUdRQBeNOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPECIAL_TOKENS = [tokenizer.pad_token_id, \n",
        "                  tokenizer.cls_token_id, \n",
        "                  tokenizer.sep_token_id]\n",
        "NULL_LABEL_ID  = -100\n",
        "\n",
        "def label_sentences(input_ids, labels):\n",
        "  \"\"\"\n",
        "  BERT will add tokens and break apart unknown tokens\n",
        "  We encode these with our null indicator and label the tokens with our index\n",
        "  \n",
        "  For example:\n",
        "  * We have the sentence: Robert Deniro\n",
        "  * Our tokens are      : B-Actor, I-Actor\n",
        "  * Our token map       : B-Actor : 0\n",
        "                        : I-Actor : 18\n",
        "  * BERT made it [CLS] Rob ##ert De ##ni ##ro [SEP] [PAD] ...\n",
        "  * We need to apply our BIO tokens into the BERT tokenized list\n",
        "    - Skip any special tokens BERT adds\n",
        "    - Skip any ## tokens\n",
        "    - Then apply our token\n",
        "  * Our BERT encoded value should be -100, 0, -100, 18, -100, -100, -100 ...\n",
        "  \"\"\"\n",
        "  new_labels = []\n",
        "\n",
        "  for (sentence, orig_labels) in zip(input_ids, labels):\n",
        "      padded_labels = []\n",
        "      orig_labels_index = 0 \n",
        "\n",
        "      for token_id in sentence:\n",
        "        token_id = token_id.numpy().item()\n",
        "\n",
        "        if token_id in SPECIAL_TOKENS or tokenizer.ids_to_tokens[token_id][0:2] == '##':  \n",
        "          padded_labels.append(NULL_LABEL_ID)\n",
        "        else:\n",
        "          label_str = orig_labels[orig_labels_index]\n",
        "          padded_labels.append(label2id[label_str])\n",
        "          orig_labels_index += 1\n",
        "\n",
        "      new_labels.append(padded_labels)\n",
        "\n",
        "  return new_labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnUZn-HD5etO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_labels = label_sentences(input_ids, labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyVRBXPh6yRT",
        "colab_type": "text"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqitEA1WhnhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "3868b754-134a-45ad-9994-b6310a8a20bd"
      },
      "source": [
        "print('\\nSentence:    ', sentences[2])\n",
        "print('\\nLabels:      ', labels[2])\n",
        "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
        "print('\\nToken IDs:   ', input_ids[2])\n",
        "print('\\nNew Labels:  ', new_labels[2])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentence:     ['what', 'movies', 'starred', 'both', 'al', 'pacino', 'and', 'robert', 'deniro']\n",
            "\n",
            "Labels:       ['O', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR', 'O', 'B-ACTOR', 'I-ACTOR']\n",
            "\n",
            "BERT Tokens:  ['what', 'movies', 'starred', 'both', 'al', 'pac', '##ino', 'and', 'robert', 'den', '##iro']\n",
            "\n",
            "Token IDs:    tensor([  101,  2054,  5691,  5652,  2119,  2632, 14397,  5740,  1998,  2728,\n",
            "         7939,  9711,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "\n",
            "New Labels:   [-100, 0, 0, 0, 0, 13, 15, -100, 0, 13, 15, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlAnnFnWmTJ_",
        "colab_type": "text"
      },
      "source": [
        "## Tokens to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MREOQysi58z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_tensors(input_ids, attention_masks, new_labels):\n",
        "  \"\"\"\n",
        "  Create pytorch tensors of correct size to train \n",
        "  \"\"\"\n",
        "  pt_input_ids       = torch.stack(input_ids, dim=0)\n",
        "  pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
        "  pt_labels          = torch.tensor(new_labels, dtype=torch.long)\n",
        "  return pt_input_ids, pt_attention_masks, pt_labels\n",
        "\n",
        "pt_input_ids, pt_attention_masks, pt_labels = \\\n",
        "  tokens_to_tensors(input_ids, attention_masks, new_labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnbobDuGcWgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f7175e74-c0e6-47bb-80a5-5a9411968c27"
      },
      "source": [
        "print('PyTorch Tensor Input Embeddings')\n",
        "print(pt_input_ids)\n",
        "\n",
        "print('PyTorch Tensor Attention Masks')\n",
        "print(pt_attention_masks)\n",
        "\n",
        "print('PyTorch Tensor Labels')\n",
        "print(pt_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Tensor Input Embeddings\n",
            "tensor([[ 101, 2054, 5691,  ...,    0,    0,    0],\n",
            "        [ 101, 2265, 2033,  ...,    0,    0,    0],\n",
            "        [ 101, 2054, 5691,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2054, 2079,  ...,    0,    0,    0],\n",
            "        [ 101, 2265, 2033,  ...,    0,    0,    0],\n",
            "        [ 101, 1045, 2215,  ...,    0,    0,    0]])\n",
            "PyTorch Tensor Attention Masks\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "PyTorch Tensor Labels\n",
            "tensor([[-100,    0,    0,  ..., -100, -100, -100],\n",
            "        [-100,    0,    0,  ..., -100, -100, -100],\n",
            "        [-100,    0,    0,  ..., -100, -100, -100],\n",
            "        ...,\n",
            "        [-100,    0,    0,  ..., -100, -100, -100],\n",
            "        [-100,    0,    0,  ..., -100, -100, -100],\n",
            "        [-100,    0,    0,  ..., -100, -100, -100]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWPVA_4tUyfv",
        "colab_type": "text"
      },
      "source": [
        "# BERT & Transformers\n",
        "* Images from http://jalammar.github.io/\n",
        "* For our example, we're using a length of 50\n",
        "\n",
        "![alt text](http://jalammar.github.io/images/bert-input-output.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAfqxg6rVZz_",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://jalammar.github.io/images/bert-encoders-input.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3RnCSSnVdJb",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://jalammar.github.io/images/t/encoder_with_tensors_2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWVKEN39WPRI",
        "colab_type": "text"
      },
      "source": [
        "## Self-Attention \n",
        "* Query\n",
        "* Key\n",
        "* Value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMe4Lw9mV92P",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://jalammar.github.io/images/t/self-attention-matrix-calculation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opuKHDduWaPe",
        "colab_type": "text"
      },
      "source": [
        "## Output - Z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0pL6NscWU3N",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC-qNY3GXH16",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPGbep_nXAzZ",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp36Pt7uRnqt",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wizN4kAGmSBH",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bme7_wDTmShU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f4c39eb-1be8-49d1-e66c-c99718236117"
      },
      "source": [
        "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size   = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(f'{train_size:,} training examples')\n",
        "print(f'{val_size:,} validation examples')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8,797 training examples\n",
            "978 validation examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEyxTlZrma8v",
        "colab_type": "text"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAhh5Y9S78kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8fEaCumeeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = BATCH_SIZE)\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = BATCH_SIZE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA6gc-3Umsw-",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boVugC0ZmuEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "133c8327261444f7be7040a5cccdf4d2",
            "3fb06abfa7e24c83a9b89a64d48c798c",
            "be72c06a01dd48508dbc75b7588808d3",
            "d31de5c49808491298d12b77725e4c8b",
            "801187a9b80a4b538135149009a8e500",
            "36a550ee86fb4ab1a6a2a3c75a2b3537",
            "eadd153182ad4d51bbc39ebb22f39096",
            "8e316e572c364ab59e80475fc43d028a",
            "f260f0941afd4203ad15a0cdd84329c6",
            "2629a20ec2004ffa8cd87979aff4b9f5",
            "1bfd6f8ee5164879a16eb3e2c01a3772",
            "a634700ae350496483eaadfd62458072",
            "2aa46d5b963e40c1afa2516a570debe0",
            "fec273a76fd84c75992a4afcb0f3b6f8",
            "5f6c3e5d4cd14ae5961eaa28d440c662",
            "bb4c132e6119424db5dbedc0e84a6935"
          ]
        },
        "outputId": "27251492-ce6d-4239-8c32-dbeb33dcb7aa"
      },
      "source": [
        "# Load BertForTokenClassification \n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = len(label2id) + 1, \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False)\n",
        "\n",
        "# Run model on GPU.\n",
        "model.cuda();"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "133c8327261444f7be7040a5cccdf4d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f260f0941afd4203ad15a0cdd84329c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Cn4omPovwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1db5c2a6-540c-4323-f7c8-755853ac9d87"
      },
      "source": [
        "model"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWu5-XFpm0qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 5e-5, eps = 1e-8)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhVHDOivm22d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 4\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1WTY6sTofmL",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://huggingface.co/transformers/_images/warmup_linear_schedule.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7RFFJCYnINC",
        "colab_type": "text"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKMI1n9onMSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    return str(datetime.timedelta(seconds=int(round(elapsed))))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUtTTlVinJSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "4bafcfad-d25d-4144-be22-0899b5845886"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "# Includes refinements from Chris McCormick AI https://www.chrismccormick.ai/\n",
        "seed_val = 1337\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, EPOCHS):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    275.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    275.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    275.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    275.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    275.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    275.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:02:22\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    275.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    275.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    275.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    275.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    275.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    275.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:02:22\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    275.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    275.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    275.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    275.    Elapsed: 0:01:23.\n",
            "  Batch   200  of    275.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    275.    Elapsed: 0:02:04.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:02:22\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    275.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    275.    Elapsed: 0:00:41.\n",
            "  Batch   120  of    275.    Elapsed: 0:01:02.\n",
            "  Batch   160  of    275.    Elapsed: 0:01:22.\n",
            "  Batch   200  of    275.    Elapsed: 0:01:43.\n",
            "  Batch   240  of    275.    Elapsed: 0:02:03.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:02:21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GidKWI2HRx3C",
        "colab_type": "text"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4o65e2VGkxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "d334efcb-5d18-4abe-cda6-81bca1448375"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(loss_values)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jaL2K-Pppmw",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak-ROBbeqtaZ",
        "colab_type": "text"
      },
      "source": [
        "## Load Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsqXyyOapyFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentences, test_labels = read_bio('./engtest.bio')\n",
        "test_input_ids, test_attention_masks = tokenize(test_sentences)\n",
        "test_new_labels = label_sentences(test_input_ids, test_labels)\n",
        "test_pt_input_ids, test_pt_attention_masks, test_pt_labels = \\\n",
        "  tokens_to_tensors(test_input_ids, test_attention_masks, test_new_labels)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-SWvgBFrJNB",
        "colab_type": "text"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHhx4qcqsY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_data = TensorDataset(test_pt_input_ids, test_pt_attention_masks, test_pt_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bx7ZSKyrWiy",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QXE_DZVrYTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa0a012d-c01e-4b6f-c3d7-c26a0db2887e"
      },
      "source": [
        "print(f'Predicting labels for {len(test_pt_input_ids):,} test set')\n",
        "\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  \n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack from dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Don't compute gradients\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logits\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move predictions & labels to cpu\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,443 test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zx0zhFjrtCS",
        "colab_type": "text"
      },
      "source": [
        "## Convert\n",
        "* We get a softmax of predictions per label by label type (for each sentence)\n",
        "* We take the largest probability as the label\n",
        "* Then flatten the sentences which gives us prediction per token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_FBVqmJrmIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b07a85fb-bd27-4260-fed4-4a800b73a0e0"
      },
      "source": [
        "# First, combine the results across the batches.\n",
        "all_predictions = np.concatenate(predictions, axis=0)\n",
        "all_true_labels = np.concatenate(true_labels, axis=0)\n",
        "print(f'Predictions shape: {all_predictions.shape}')\n",
        "\n",
        "# Pick argmax from predicted label scores\n",
        "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
        "print(f'Argmax shape: {predicted_label_ids.shape}')\n",
        "\n",
        "# Eliminate axis 0, sentences.\n",
        "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
        "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
        "\n",
        "print(f'Flattened: {predicted_label_ids.shape}')\n",
        "print(f'Ground truth: {all_true_labels.shape}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions shape: (2443, 50, 26)\n",
            "Argmax shape: (2443, 50)\n",
            "Flattened: (122150,)\n",
            "Ground truth: (122150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHpkP84SAiE7",
        "colab_type": "text"
      },
      "source": [
        "## Filter\n",
        "* Strip out predictions on BERT tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Twlao9rrYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "deb3c24f-b48a-4830-fbee-4613fa8e3993"
      },
      "source": [
        "real_token_predictions = []\n",
        "real_token_labels = []\n",
        "\n",
        "for i in range(len(all_true_labels)):\n",
        "    if not all_true_labels[i] == NULL_LABEL_ID:\n",
        "        real_token_predictions.append(predicted_label_ids[i])\n",
        "        real_token_labels.append(all_true_labels[i])\n",
        "\n",
        "print(f'Before filtering : {len(all_true_labels):,}')\n",
        "print(f'After filtering  : {len(real_token_labels):,}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before filtering : 122,150\n",
            "After filtering  : 24,686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jjvn0ZdryUI",
        "colab_type": "text"
      },
      "source": [
        "## Score\n",
        "* MIT Movie Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbLpUCsDsMGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "556751a1-0f31-4a73-9046-f1688434ac1f"
      },
      "source": [
        "ivd = {v: k for k, v in label2id.items()}\n",
        "friendly_labels = [ivd[i] for i in range(len(ivd))]\n",
        "print(classification_report(real_token_labels, real_token_predictions, \n",
        "                            target_names=friendly_labels, zero_division=False))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "                O       0.97      0.98      0.97     14929\n",
            "          B-GENRE       0.94      0.96      0.95      1117\n",
            "      B-CHARACTER       0.66      0.68      0.67        90\n",
            "       B-DIRECTOR       0.94      0.88      0.91       456\n",
            "         I-RATING       0.95      0.93      0.94       226\n",
            "         B-RATING       0.97      0.98      0.97       500\n",
            "      I-CHARACTER       0.61      0.55      0.58        75\n",
            "          I-GENRE       0.87      0.76      0.81       222\n",
            "           I-PLOT       0.78      0.68      0.73       496\n",
            "I-RATINGS_AVERAGE       0.88      0.92      0.90       403\n",
            "          I-TITLE       0.92      0.93      0.92       856\n",
            "B-RATINGS_AVERAGE       0.92      0.92      0.92       451\n",
            "          B-TITLE       0.88      0.89      0.89       562\n",
            "          B-ACTOR       0.92      0.95      0.94       812\n",
            "           I-YEAR       0.96      0.97      0.97       610\n",
            "          I-ACTOR       0.92      0.95      0.94       862\n",
            "        I-TRAILER       0.00      0.00      0.00         8\n",
            "           B-YEAR       0.94      0.96      0.95       720\n",
            "         I-REVIEW       0.50      0.16      0.24        45\n",
            "         B-REVIEW       0.51      0.32      0.40        56\n",
            "        B-TRAILER       0.82      0.90      0.86        30\n",
            "           I-SONG       0.93      0.78      0.85       119\n",
            "           B-PLOT       0.79      0.77      0.78       491\n",
            "       I-DIRECTOR       0.95      0.86      0.91       496\n",
            "           B-SONG       0.75      0.72      0.74        54\n",
            "\n",
            "         accuracy                           0.95     24686\n",
            "        macro avg       0.81      0.78      0.79     24686\n",
            "     weighted avg       0.94      0.95      0.94     24686\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5zWoCUSJZhQ",
        "colab_type": "text"
      },
      "source": [
        "# Closing\n",
        "* Pre-Transformers\n",
        "  * Paper 2018 https://www.aclweb.org/anthology/W18-5711.pdf\n",
        "  * F1-Score : 87.41\n",
        "  * BERT (Base, Uncased) : 94-95%\n",
        "* Improving\n",
        "  * Bigger BERT\n",
        "  * More training data\n",
        "  * Speed https://github.com/hanxiao/bert-as-service\n",
        "* NLP Classification Tasks\n",
        "  * Document\n",
        "  * Sentence\n",
        "  * Token\n",
        "* Alternative Libraries\n",
        "  * SpaCy\n",
        "  * Stanford NER \n",
        "* Resources\n",
        "  * http://jalammar.github.io/illustrated-bert/\n",
        "  * https://www.chrismccormick.ai/\n",
        "  * https://github.com/cedrickchee/awesome-bert-nlp\n",
        "  * https://arxiv.org/pdf/1804.00247.pdf\n",
        "  * https://www.tensorflow.org/official_models/fine_tuning_bert\n",
        "  * https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUmf6yKEO6fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}