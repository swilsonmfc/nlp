{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BagOfWords.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOQKlslPwA+FMMJDF1wpCzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swilsonmfc/nlp/blob/master/BagOfWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5XIrPLDoxe9"
      },
      "source": [
        "# BOW\n",
        "* Read in a corpus of text\n",
        "* Convert to a Bag of Words\n",
        "  * Word : Frequency\n",
        "* Complete task using a variety of mechanisms\n",
        "  * Python\n",
        "  * DefaultDict\n",
        "  * CountVectorizer\n",
        "  * FreqDist\n",
        "  * Gensim\n",
        "  * Spacy\n",
        "  * TextBlob\n",
        "* Review Common Preprocessing to BOW\n",
        "* Apply TF-IDF\n",
        "\n",
        "![](https://miro.medium.com/max/600/0*JpqZhCNsQ_OGaRkB.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y_MQaXqo2i6"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suu54Jp0phHC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import nltk.stem\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "from gensim import models\n",
        "from gensim import corpora\n",
        "\n",
        "import spacy\n",
        "\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtziOO6nptLx"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61S5no9URfb",
        "outputId": "b3a1b8ec-782d-4f12-9647-9045b2591ae5"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1CXmri0DSP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769562eb-9f3f-4453-9385-d153469c9950"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M2pL4nMqhmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9d3ca0-3a1a-4ab4-ad6c-05830743d113"
      },
      "source": [
        "nltk.download('gutenberg')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1l7n0DTpuIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e3ddda-a6cb-4529-ad34-8d336797ebdb"
      },
      "source": [
        "hamlet       = gutenberg.words('shakespeare-hamlet.txt')\n",
        "hamlet_raw   = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "hamlet_sents = gutenberg.sents('shakespeare-hamlet.txt')\n",
        "len(hamlet)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37360"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOPHHzXfq4cS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b49dffe-2fe3-44f6-fa4d-fdd7fbcd2574"
      },
      "source": [
        "counter = 0\n",
        "for word in hamlet:\n",
        "  print(word)\n",
        "  counter += 1\n",
        "  if counter > 20:\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "The\n",
            "Tragedie\n",
            "of\n",
            "Hamlet\n",
            "by\n",
            "William\n",
            "Shakespeare\n",
            "1599\n",
            "]\n",
            "Actus\n",
            "Primus\n",
            ".\n",
            "Scoena\n",
            "Prima\n",
            ".\n",
            "Enter\n",
            "Barnardo\n",
            "and\n",
            "Francisco\n",
            "two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV0-_zVKDOjy"
      },
      "source": [
        "# Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh7ytITGuj8C"
      },
      "source": [
        "## Dictionary\n",
        "* Loop through the words\n",
        "* Each time we see a word increment the counter in the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVx8ocaqyint",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0986934-bfbe-4364-c838-260dd235f3ed"
      },
      "source": [
        "diy_bow = {}\n",
        "for word in hamlet:\n",
        "  diy_bow.setdefault(word, 0) \n",
        "  diy_bow[word] += 1\n",
        "\n",
        "print(f'There are {len(hamlet):,} tokens in Hamlet')\n",
        "print(f'There are {len(diy_bow):,} unique tokens in Hamlet')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 37,360 tokens in Hamlet\n",
            "There are 5,447 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8CVWV5j-RJs"
      },
      "source": [
        "## DefaultDict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY0wLiX5-Tn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f84927e-80ae-4398-962d-ed9cecfa99ab"
      },
      "source": [
        "frequency = defaultdict(int)\n",
        "for token in hamlet:\n",
        "  frequency[token] += 1\n",
        "\n",
        "print(f'There are {len(hamlet):,} tokens in Hamlet')\n",
        "print(f'There are {len(frequency):,} unique tokens in Hamlet')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 37,360 tokens in Hamlet\n",
            "There are 5,447 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2al-Vho2RC"
      },
      "source": [
        "## FreqDist\n",
        "* FreqDist is a subset of Dictionary\n",
        "* To get the unigrams in the dictionary, cast it to dict\n",
        "* Helper class in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoRWL3TBFSC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a066f6-de6a-4360-ed40-ad6336e64e04"
      },
      "source": [
        "fdist_manual = FreqDist()\n",
        "for word in hamlet:\n",
        "  fdist_manual[word] += 1\n",
        "\n",
        "fdist = FreqDist([word for word in hamlet])\n",
        "\n",
        "print(f'There are {len(hamlet):,} tokens in Hamlet')\n",
        "print(f'There are {len(fdist):,} unique tokens in Hamlet')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 37,360 tokens in Hamlet\n",
            "There are 5,447 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od1mgGzAF5SN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f2fd30-b196-49ad-b554-32baa5666877"
      },
      "source": [
        "d = dict(fdist)\n",
        "freq = [(k, d[k]) for k in sorted(d, key=d.get, reverse=True)]\n",
        "print(freq[0:20])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 2892), ('.', 1886), ('the', 860), (\"'\", 729), ('and', 606), ('of', 576), ('to', 576), (':', 565), ('I', 553), ('you', 479), ('?', 459), ('a', 449), ('my', 435), ('in', 359), ('it', 354), ('Ham', 337), ('is', 304), (';', 298), ('not', 286), ('his', 266)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtTrcRdro2fn"
      },
      "source": [
        "## CountVectorizer\n",
        "* Class in sklearn\n",
        "* Can build NGrams\n",
        "* Handles some preprocessing (lower)\n",
        "* Has code for word boundaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfZD11Ftz6Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db766cb2-e925-4a05-89ec-92c8af1d3eb8"
      },
      "source": [
        "count_vec = CountVectorizer()\n",
        "count_vec.fit_transform(hamlet)\n",
        "print(f'There are {len(count_vec.get_feature_names()):,} unique tokens in Hamlet')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4,688 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pny-8lNXLG6j",
        "outputId": "15ac5c29-1988-45af-c3af-5197ff64a4f7"
      },
      "source": [
        "count_vec = CountVectorizer(lowercase=False)\n",
        "count_vec.fit_transform(hamlet)\n",
        "print(f'There are {len(count_vec.get_feature_names()):,} unique tokens in Hamlet')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5,411 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEv8cR30rXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2cc0cbf-94d0-4302-d11d-0587906186a9"
      },
      "source": [
        "diffs = set.difference(set(diy_bow.keys()), count_vec.get_feature_names())\n",
        "diffs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '1',\n",
              " ':',\n",
              " ':)',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'E',\n",
              " 'I',\n",
              " 'K',\n",
              " 'L',\n",
              " 'O',\n",
              " 'S',\n",
              " 'T',\n",
              " 'Y',\n",
              " '[',\n",
              " ']',\n",
              " '].',\n",
              " 'a',\n",
              " 'd',\n",
              " 'e',\n",
              " 'i',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 's',\n",
              " 't',\n",
              " 'y'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wS-Lo9eTtGK"
      },
      "source": [
        "## CountVectorizer - NGrams\n",
        "* Bag of Words = BOW\n",
        "* Bag of N Grams = ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOAOeXNzH0Gy",
        "outputId": "5da54a3e-b78e-4c27-8f15-49a869e606fc"
      },
      "source": [
        "count_ngram_vec = CountVectorizer(ngram_range=(1, 2))\n",
        "fitted = count_ngram_vec.fit_transform([hamlet_raw])\n",
        "\n",
        "print(f'There are {len(count_ngram_vec.get_feature_names()):,} unique Uni & Bi Grams in Hamlet')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 25,506 unique Uni & Bi Grams in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cQ1fxr1XJvBz",
        "outputId": "9580f6e0-175e-4083-b1e9-a9e395ca2f3a"
      },
      "source": [
        "most = fitted.toarray().argmax()\n",
        "count_ngram_vec.get_feature_names()[most]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lfNc2tw81w-"
      },
      "source": [
        "## Gensim\n",
        "* It expects a list of documents, where each document is a list of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji0Gbq5B825x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16570c2a-0278-4aaf-fab8-7bf85615573e"
      },
      "source": [
        "words = [word for word in hamlet]\n",
        "gensim_dict = corpora.Dictionary([words])\n",
        "\n",
        "print(f'There are {len(hamlet):,} tokens in Hamlet')\n",
        "print(f'There are {len(gensim_dict):,} unique tokens in Hamlet')\n",
        "\n",
        "print(f'There was {gensim_dict.num_docs:,} documents loaded.')\n",
        "print(f'There was {gensim_dict.num_nnz:,} unique tokens loaded.')\n",
        "print(f'There was {gensim_dict.num_pos:,} words loaded.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 37,360 tokens in Hamlet\n",
            "There are 5,447 unique tokens in Hamlet\n",
            "There was 1 documents loaded.\n",
            "There was 5,447 unique tokens loaded.\n",
            "There was 37,360 words loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQXVumc9jGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a38c66c-589c-48ec-b9bb-c65add6906bc"
      },
      "source": [
        "bow = gensim_dict.doc2bow(document=hamlet)\n",
        "[(gensim_dict.get(id), freq) for id, freq in bow][0:20]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('!', 17),\n",
              " ('&', 25),\n",
              " (\"'\", 729),\n",
              " ('(', 45),\n",
              " (')', 43),\n",
              " (',', 2892),\n",
              " ('-', 117),\n",
              " ('.', 1886),\n",
              " ('1', 4),\n",
              " ('1599', 1),\n",
              " (':', 565),\n",
              " (':)', 1),\n",
              " (';', 298),\n",
              " ('?', 459),\n",
              " ('A', 62),\n",
              " ('Aboord', 1),\n",
              " ('About', 3),\n",
              " ('Abridgements', 1),\n",
              " ('Absent', 1),\n",
              " ('Abstracts', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egLSu1jrASqp"
      },
      "source": [
        "## SpaCy\n",
        "* Operates against a raw text string\n",
        "* Applies a pipeline to the processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiYd3_GgAZlh"
      },
      "source": [
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4-XceNRQQYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb155beb-ed0d-4f33-ea3b-bee786792577"
      },
      "source": [
        "spacy_doc = nlp(hamlet_raw)\n",
        "\n",
        "print(f'Spacy identified {spacy_doc.vocab.length:,} tokens')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spacy identified 5,931 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM5GAuLIOVnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199a1ca2-42fc-49e6-ae5f-027f58ab9156"
      },
      "source": [
        "words = [token.text for token in spacy_doc]\n",
        "word_freq = Counter(words)\n",
        "common_words = word_freq.most_common(20)\n",
        "print (common_words)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 2892), ('\\n', 2752), ('.', 1846), ('the', 860), ('\\n\\n   ', 734), ('and', 605), ('of', 576), ('to', 574), (':', 566), ('I', 549), ('you', 474), ('?', 459), ('a', 447), ('my', 435), ('it', 354), ('in', 348), ('Ham', 337), ('not', 313), (';', 298), ('is', 292)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-aGCch4QdXd"
      },
      "source": [
        "## TextBlob\n",
        "* Operates against a raw string\n",
        "* Applies a tokenizer and other components to the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYxFItx47CyF"
      },
      "source": [
        "tb = TextBlob(hamlet_raw)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNFc1je-8_qS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699d0d75-a9cc-4f82-bb32-017861dbcf10"
      },
      "source": [
        "tb.word_counts"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'the': 993,\n",
              "             'tragedie': 4,\n",
              "             'of': 610,\n",
              "             'hamlet': 100,\n",
              "             'by': 105,\n",
              "             'william': 1,\n",
              "             'shakespeare': 1,\n",
              "             '1599': 1,\n",
              "             'actus': 2,\n",
              "             'primus': 1,\n",
              "             'scoena': 1,\n",
              "             'prima': 1,\n",
              "             'enter': 85,\n",
              "             'barnardo': 8,\n",
              "             'and': 862,\n",
              "             'francisco': 2,\n",
              "             'two': 21,\n",
              "             'centinels': 1,\n",
              "             'who': 42,\n",
              "             's': 121,\n",
              "             'there': 92,\n",
              "             'fran': 8,\n",
              "             'nay': 26,\n",
              "             'answer': 9,\n",
              "             'me': 228,\n",
              "             'stand': 15,\n",
              "             'vnfold': 3,\n",
              "             'your': 253,\n",
              "             'selfe': 67,\n",
              "             'bar': 7,\n",
              "             'long': 17,\n",
              "             'liue': 14,\n",
              "             'king': 172,\n",
              "             'he': 202,\n",
              "             'you': 522,\n",
              "             'come': 104,\n",
              "             'most': 77,\n",
              "             'carefully': 1,\n",
              "             'vpon': 50,\n",
              "             'houre': 5,\n",
              "             't': 65,\n",
              "             'is': 372,\n",
              "             'now': 92,\n",
              "             'strook': 1,\n",
              "             'twelue': 5,\n",
              "             'get': 9,\n",
              "             'thee': 58,\n",
              "             'to': 683,\n",
              "             'bed': 11,\n",
              "             'for': 243,\n",
              "             'this': 275,\n",
              "             'releefe': 1,\n",
              "             'much': 43,\n",
              "             'thankes': 9,\n",
              "             'bitter': 3,\n",
              "             'cold': 6,\n",
              "             'i': 560,\n",
              "             'am': 52,\n",
              "             'sicke': 3,\n",
              "             'at': 81,\n",
              "             'heart': 29,\n",
              "             'barn': 10,\n",
              "             'haue': 175,\n",
              "             'had': 44,\n",
              "             'quiet': 5,\n",
              "             'guard': 3,\n",
              "             'not': 327,\n",
              "             'a': 497,\n",
              "             'mouse': 2,\n",
              "             'stirring': 1,\n",
              "             'well': 70,\n",
              "             'goodnight': 9,\n",
              "             'if': 111,\n",
              "             'do': 101,\n",
              "             'meet': 4,\n",
              "             'horatio': 40,\n",
              "             'marcellus': 10,\n",
              "             'riuals': 1,\n",
              "             'my': 502,\n",
              "             'watch': 14,\n",
              "             'bid': 6,\n",
              "             'them': 67,\n",
              "             'make': 54,\n",
              "             'hast': 27,\n",
              "             'thinke': 42,\n",
              "             'heare': 30,\n",
              "             'hor': 95,\n",
              "             'friends': 19,\n",
              "             'ground': 8,\n",
              "             'mar': 31,\n",
              "             'leige-men': 1,\n",
              "             'dane': 6,\n",
              "             'giue': 59,\n",
              "             'good': 98,\n",
              "             'night': 38,\n",
              "             'o': 58,\n",
              "             'farwel': 1,\n",
              "             'honest': 11,\n",
              "             'soldier': 2,\n",
              "             'hath': 57,\n",
              "             'relieu': 1,\n",
              "             'd': 200,\n",
              "             'fra': 1,\n",
              "             'ha': 25,\n",
              "             'place': 6,\n",
              "             'exit': 18,\n",
              "             'holla': 1,\n",
              "             'say': 51,\n",
              "             'what': 211,\n",
              "             'peece': 6,\n",
              "             'him': 178,\n",
              "             'welcome': 16,\n",
              "             'thing': 25,\n",
              "             'appear': 2,\n",
              "             'againe': 34,\n",
              "             'seene': 20,\n",
              "             'nothing': 27,\n",
              "             'saies': 3,\n",
              "             'but': 249,\n",
              "             'our': 130,\n",
              "             'fantasie': 2,\n",
              "             'will': 149,\n",
              "             'let': 104,\n",
              "             'beleefe': 1,\n",
              "             'take': 32,\n",
              "             'hold': 25,\n",
              "             'touching': 3,\n",
              "             'dreaded': 1,\n",
              "             'sight': 8,\n",
              "             'twice': 4,\n",
              "             'vs': 64,\n",
              "             'therefore': 14,\n",
              "             'intreated': 1,\n",
              "             'along': 3,\n",
              "             'with': 254,\n",
              "             'minutes': 1,\n",
              "             'that': 376,\n",
              "             'apparition': 2,\n",
              "             'may': 65,\n",
              "             'approue': 1,\n",
              "             'eyes': 20,\n",
              "             'speake': 55,\n",
              "             'it': 419,\n",
              "             'tush': 2,\n",
              "             'twill': 4,\n",
              "             'appeare': 3,\n",
              "             'sit': 8,\n",
              "             'downe': 26,\n",
              "             'a-while': 3,\n",
              "             'once': 19,\n",
              "             'assaile': 1,\n",
              "             'eares': 9,\n",
              "             'are': 121,\n",
              "             'so': 189,\n",
              "             'fortified': 1,\n",
              "             'against': 20,\n",
              "             'story': 2,\n",
              "             'we': 128,\n",
              "             'nights': 4,\n",
              "             'last': 13,\n",
              "             'all': 109,\n",
              "             'when': 51,\n",
              "             'yond': 1,\n",
              "             'same': 13,\n",
              "             'starre': 4,\n",
              "             'westward': 1,\n",
              "             'from': 87,\n",
              "             'pole': 2,\n",
              "             'made': 29,\n",
              "             'his': 285,\n",
              "             'course': 5,\n",
              "             'illume': 1,\n",
              "             'part': 18,\n",
              "             'heauen': 43,\n",
              "             'where': 56,\n",
              "             'burnes': 2,\n",
              "             'bell': 2,\n",
              "             'then': 108,\n",
              "             'beating': 3,\n",
              "             'one': 46,\n",
              "             'peace': 9,\n",
              "             'breake': 8,\n",
              "             'ghost': 21,\n",
              "             'looke': 31,\n",
              "             'comes': 23,\n",
              "             'in': 388,\n",
              "             'figure': 4,\n",
              "             'like': 77,\n",
              "             'dead': 30,\n",
              "             'thou': 105,\n",
              "             'art': 16,\n",
              "             'scholler': 1,\n",
              "             'lookes': 7,\n",
              "             'marke': 13,\n",
              "             'hora': 9,\n",
              "             'harrowes': 1,\n",
              "             'fear': 1,\n",
              "             'wonder': 3,\n",
              "             'would': 68,\n",
              "             'be': 191,\n",
              "             'spoke': 2,\n",
              "             'too': 53,\n",
              "             'question': 14,\n",
              "             \"vsurp'st\": 1,\n",
              "             'time': 44,\n",
              "             'together': 10,\n",
              "             'faire': 20,\n",
              "             'warlike': 4,\n",
              "             'forme': 12,\n",
              "             'which': 60,\n",
              "             'maiesty': 8,\n",
              "             'buried': 6,\n",
              "             'denmarke': 20,\n",
              "             'did': 60,\n",
              "             'sometimes': 5,\n",
              "             'march': 5,\n",
              "             'charge': 7,\n",
              "             'offended': 3,\n",
              "             'see': 46,\n",
              "             'stalkes': 1,\n",
              "             'away': 27,\n",
              "             'stay': 11,\n",
              "             'gone': 13,\n",
              "             'how': 89,\n",
              "             'tremble': 2,\n",
              "             'look': 7,\n",
              "             'pale': 8,\n",
              "             'something': 12,\n",
              "             'more': 89,\n",
              "             \"n't\": 20,\n",
              "             'before': 17,\n",
              "             'god': 25,\n",
              "             'might': 30,\n",
              "             'beleeue': 17,\n",
              "             'without': 13,\n",
              "             'sensible': 2,\n",
              "             'true': 21,\n",
              "             'auouch': 1,\n",
              "             'mine': 44,\n",
              "             'owne': 31,\n",
              "             'as': 205,\n",
              "             'thy': 90,\n",
              "             'such': 52,\n",
              "             'was': 85,\n",
              "             'very': 49,\n",
              "             'armour': 2,\n",
              "             'on': 123,\n",
              "             'th': 33,\n",
              "             'ambitious': 3,\n",
              "             'norwey': 5,\n",
              "             'combatted': 1,\n",
              "             'frown': 1,\n",
              "             'an': 53,\n",
              "             'angry': 1,\n",
              "             'parle': 1,\n",
              "             'smot': 1,\n",
              "             'sledded': 1,\n",
              "             'pollax': 1,\n",
              "             'ice': 2,\n",
              "             'strange': 9,\n",
              "             'thus': 41,\n",
              "             'iust': 3,\n",
              "             'martiall': 1,\n",
              "             'stalke': 1,\n",
              "             'particular': 5,\n",
              "             'thought': 13,\n",
              "             'work': 1,\n",
              "             'know': 69,\n",
              "             'grosse': 2,\n",
              "             'scope': 2,\n",
              "             'opinion': 1,\n",
              "             'boades': 1,\n",
              "             'some': 45,\n",
              "             'erruption': 1,\n",
              "             'state': 13,\n",
              "             'tell': 43,\n",
              "             'knowes': 3,\n",
              "             'why': 60,\n",
              "             'strict': 1,\n",
              "             'obseruant': 1,\n",
              "             'nightly': 2,\n",
              "             'toyles': 1,\n",
              "             'subiect': 3,\n",
              "             'land': 5,\n",
              "             'dayly': 1,\n",
              "             'cast': 6,\n",
              "             'brazon': 1,\n",
              "             'cannon': 4,\n",
              "             'forraigne': 1,\n",
              "             'mart': 1,\n",
              "             'implements': 1,\n",
              "             'warre': 2,\n",
              "             'impresse': 1,\n",
              "             'ship-wrights': 1,\n",
              "             'whose': 27,\n",
              "             'sore': 3,\n",
              "             'taske': 1,\n",
              "             'diuide': 1,\n",
              "             'sunday': 1,\n",
              "             'weeke': 1,\n",
              "             'toward': 4,\n",
              "             'sweaty': 1,\n",
              "             'doth': 27,\n",
              "             'ioynt-labourer': 1,\n",
              "             'day': 24,\n",
              "             \"is't\": 13,\n",
              "             'can': 61,\n",
              "             'informe': 1,\n",
              "             'least': 3,\n",
              "             'whisper': 1,\n",
              "             'goes': 13,\n",
              "             'image': 4,\n",
              "             'euen': 21,\n",
              "             'fortinbras': 13,\n",
              "             'norway': 4,\n",
              "             'thereto': 1,\n",
              "             'prick': 1,\n",
              "             'emulate': 1,\n",
              "             'pride': 1,\n",
              "             'dar': 1,\n",
              "             'combate': 1,\n",
              "             'valiant': 3,\n",
              "             'side': 2,\n",
              "             'knowne': 7,\n",
              "             'world': 25,\n",
              "             'esteem': 1,\n",
              "             'slay': 1,\n",
              "             'seal': 5,\n",
              "             'compact': 1,\n",
              "             'ratified': 1,\n",
              "             'law': 7,\n",
              "             'heraldrie': 1,\n",
              "             'forfeite': 1,\n",
              "             'life': 32,\n",
              "             'those': 20,\n",
              "             'lands': 4,\n",
              "             'stood': 4,\n",
              "             'seiz': 1,\n",
              "             'conqueror': 1,\n",
              "             'moity': 1,\n",
              "             'competent': 1,\n",
              "             'gaged': 1,\n",
              "             \"return'd\": 2,\n",
              "             'inheritance': 1,\n",
              "             'bin': 7,\n",
              "             'vanquisher': 1,\n",
              "             \"cou'nant\": 1,\n",
              "             'carriage': 1,\n",
              "             'article': 1,\n",
              "             'designe': 1,\n",
              "             'fell': 8,\n",
              "             'sir': 62,\n",
              "             'young': 9,\n",
              "             'vnimproued': 1,\n",
              "             'mettle': 2,\n",
              "             'hot': 6,\n",
              "             'full': 10,\n",
              "             'skirts': 1,\n",
              "             'heere': 50,\n",
              "             'shark': 1,\n",
              "             'vp': 35,\n",
              "             'list': 6,\n",
              "             'landlesse': 1,\n",
              "             'resolutes': 1,\n",
              "             'foode': 1,\n",
              "             'diet': 2,\n",
              "             'enterprize': 2,\n",
              "             'stomacke': 1,\n",
              "             'no': 137,\n",
              "             'other': 27,\n",
              "             'vnto': 5,\n",
              "             'recouer': 3,\n",
              "             'strong': 4,\n",
              "             'hand': 19,\n",
              "             'termes': 3,\n",
              "             'compulsatiue': 1,\n",
              "             'foresaid': 1,\n",
              "             'father': 50,\n",
              "             'lost': 8,\n",
              "             'maine': 3,\n",
              "             'motiue': 4,\n",
              "             'preparations': 1,\n",
              "             'sourse': 2,\n",
              "             'cheefe': 2,\n",
              "             'head': 26,\n",
              "             'post-hast': 1,\n",
              "             'romage': 1,\n",
              "             'soft': 8,\n",
              "             'behold': 1,\n",
              "             'loe': 3,\n",
              "             'ile': 58,\n",
              "             'crosse': 1,\n",
              "             'though': 22,\n",
              "             'blast': 2,\n",
              "             'illusion': 1,\n",
              "             'any': 17,\n",
              "             'sound': 7,\n",
              "             'or': 103,\n",
              "             'vse': 13,\n",
              "             'voyce': 10,\n",
              "             'done': 21,\n",
              "             'ease': 4,\n",
              "             'grace': 12,\n",
              "             'speak': 5,\n",
              "             'priuy': 1,\n",
              "             'countries': 2,\n",
              "             'fate': 2,\n",
              "             'happily': 2,\n",
              "             'foreknowing': 1,\n",
              "             'auoyd': 2,\n",
              "             'oh': 81,\n",
              "             'vp-hoorded': 1,\n",
              "             'extorted': 1,\n",
              "             'treasure': 4,\n",
              "             'wombe': 1,\n",
              "             'earth': 21,\n",
              "             'they': 88,\n",
              "             'spirits': 5,\n",
              "             'oft': 10,\n",
              "             'walke': 9,\n",
              "             'death': 36,\n",
              "             'stop': 3,\n",
              "             'shall': 107,\n",
              "             'strike': 2,\n",
              "             'partizan': 1,\n",
              "             'wrong': 8,\n",
              "             'being': 11,\n",
              "             'maiesticall': 2,\n",
              "             'offer': 4,\n",
              "             'shew': 20,\n",
              "             'violence': 4,\n",
              "             'ayre': 12,\n",
              "             'invulnerable': 1,\n",
              "             'vaine': 1,\n",
              "             'blowes': 2,\n",
              "             'malicious': 2,\n",
              "             'mockery': 1,\n",
              "             'about': 19,\n",
              "             'cocke': 5,\n",
              "             'crew': 2,\n",
              "             'started': 1,\n",
              "             'guilty': 5,\n",
              "             'fearfull': 1,\n",
              "             'summons': 1,\n",
              "             'heard': 14,\n",
              "             'trumpet': 4,\n",
              "             'lofty': 1,\n",
              "             'shrill-sounding': 1,\n",
              "             'throate': 2,\n",
              "             'awake': 2,\n",
              "             'warning': 1,\n",
              "             'whether': 4,\n",
              "             'sea': 5,\n",
              "             'fire': 11,\n",
              "             'extrauagant': 1,\n",
              "             'erring': 1,\n",
              "             'spirit': 14,\n",
              "             'hyes': 1,\n",
              "             'confine': 2,\n",
              "             'truth': 6,\n",
              "             'heerein': 4,\n",
              "             'present': 3,\n",
              "             'obiect': 1,\n",
              "             'probation': 1,\n",
              "             'faded': 1,\n",
              "             'crowing': 1,\n",
              "             'sayes': 6,\n",
              "             'euer': 12,\n",
              "             'gainst': 5,\n",
              "             'season': 7,\n",
              "             'wherein': 4,\n",
              "             'sauiours': 1,\n",
              "             'birch': 1,\n",
              "             'celebrated': 1,\n",
              "             'bird': 2,\n",
              "             'dawning': 1,\n",
              "             'singeth': 1,\n",
              "             'abroad': 1,\n",
              "             'wholsome': 5,\n",
              "             'planets': 1,\n",
              "             'faiery': 1,\n",
              "             'talkes': 1,\n",
              "             'nor': 32,\n",
              "             'witch': 1,\n",
              "             'power': 8,\n",
              "             'charme': 1,\n",
              "             'hallow': 1,\n",
              "             'gracious': 6,\n",
              "             'morne': 2,\n",
              "             'russet': 1,\n",
              "             'mantle': 1,\n",
              "             'clad': 1,\n",
              "             'walkes': 2,\n",
              "             're': 14,\n",
              "             'dew': 3,\n",
              "             'yon': 1,\n",
              "             'high': 3,\n",
              "             'easterne': 1,\n",
              "             'hill': 3,\n",
              "             'aduice': 3,\n",
              "             'impart': 4,\n",
              "             'yong': 8,\n",
              "             'dumbe': 6,\n",
              "             'consent': 3,\n",
              "             'acquaint': 1,\n",
              "             'needfull': 2,\n",
              "             'loues': 6,\n",
              "             'fitting': 1,\n",
              "             'duty': 8,\n",
              "             \"do't\": 2,\n",
              "             'pray': 28,\n",
              "             'morning': 4,\n",
              "             'finde': 13,\n",
              "             'conueniently': 1,\n",
              "             'exeunt': 23,\n",
              "             'scena': 3,\n",
              "             'secunda': 2,\n",
              "             'claudius': 1,\n",
              "             'gertrude': 13,\n",
              "             'queene': 39,\n",
              "             'polonius': 20,\n",
              "             'laertes': 35,\n",
              "             'sister': 8,\n",
              "             'ophelia': 28,\n",
              "             'lords': 5,\n",
              "             'attendant': 4,\n",
              "             'yet': 37,\n",
              "             'deere': 20,\n",
              "             'brothers': 9,\n",
              "             'memory': 7,\n",
              "             'greene': 2,\n",
              "             'befitted': 1,\n",
              "             'beare': 13,\n",
              "             'hearts': 3,\n",
              "             'greefe': 10,\n",
              "             'whole': 8,\n",
              "             'kingdome': 5,\n",
              "             'contracted': 1,\n",
              "             'brow': 4,\n",
              "             'woe': 8,\n",
              "             'farre': 12,\n",
              "             'discretion': 4,\n",
              "             'fought': 1,\n",
              "             'nature': 24,\n",
              "             'wisest': 3,\n",
              "             'sorrow': 6,\n",
              "             'remembrance': 3,\n",
              "             'selues': 12,\n",
              "             'imperiall': 2,\n",
              "             'ioyntresse': 1,\n",
              "             'twere': 10,\n",
              "             'defeated': 1,\n",
              "             'ioy': 8,\n",
              "             'auspicious': 1,\n",
              "             'dropping': 1,\n",
              "             'eye': 14,\n",
              "             'mirth': 2,\n",
              "             'funerall': 3,\n",
              "             'dirge': 1,\n",
              "             'marriage': 6,\n",
              "             'equall': 2,\n",
              "             'scale': 2,\n",
              "             'weighing': 1,\n",
              "             'delight': 3,\n",
              "             'dole': 1,\n",
              "             'taken': 2,\n",
              "             'wife': 8,\n",
              "             \"barr'd\": 1,\n",
              "             'better': 15,\n",
              "             'wisedomes': 1,\n",
              "             'freely': 5,\n",
              "             'affaire': 3,\n",
              "             'followes': 4,\n",
              "             'holding': 1,\n",
              "             'weake': 2,\n",
              "             'supposall': 1,\n",
              "             'worth': 1,\n",
              "             'thinking': 3,\n",
              "             'late': 10,\n",
              "             'disioynt': 1,\n",
              "             'out': 52,\n",
              "             'frame': 4,\n",
              "             'colleagued': 1,\n",
              "             'dreame': 5,\n",
              "             'aduantage': 1,\n",
              "             'fayl': 1,\n",
              "             'pester': 1,\n",
              "             'message': 1,\n",
              "             'importing': 2,\n",
              "             'surrender': 1,\n",
              "             'bonds': 2,\n",
              "             'brother': 7,\n",
              "             'voltemand': 3,\n",
              "             'cornelius': 4,\n",
              "             'meeting': 2,\n",
              "             'businesse': 10,\n",
              "             'writ': 6,\n",
              "             'vncle': 3,\n",
              "             'impotent': 1,\n",
              "             'bedrid': 1,\n",
              "             'scarsely': 1,\n",
              "             'heares': 2,\n",
              "             'nephewes': 2,\n",
              "             'purpose': 12,\n",
              "             'suppresse': 2,\n",
              "             'further': 12,\n",
              "             'gate': 2,\n",
              "             'leuies': 2,\n",
              "             'lists': 1,\n",
              "             'proportions': 1,\n",
              "             'dispatch': 2,\n",
              "             'bearing': 1,\n",
              "             'greeting': 1,\n",
              "             'old': 17,\n",
              "             'giuing': 3,\n",
              "             'personall': 1,\n",
              "             'these': 44,\n",
              "             'dilated': 1,\n",
              "             'articles': 1,\n",
              "             'allow': 1,\n",
              "             'farewell': 15,\n",
              "             'commend': 4,\n",
              "             'volt': 2,\n",
              "             'things': 11,\n",
              "             'doubt': 10,\n",
              "             'heartily': 3,\n",
              "             'newes': 11,\n",
              "             'told': 5,\n",
              "             'suite': 2,\n",
              "             'reason': 12,\n",
              "             'loose': 5,\n",
              "             \"would'st\": 4,\n",
              "             'beg': 1,\n",
              "             'asking': 2,\n",
              "             'natiue': 4,\n",
              "             'instrumentall': 1,\n",
              "             'mouth': 7,\n",
              "             'throne': 2,\n",
              "             'laer': 60,\n",
              "             'dread': 5,\n",
              "             'lord': 211,\n",
              "             'leaue': 27,\n",
              "             'fauour': 4,\n",
              "             'returne': 5,\n",
              "             'france': 5,\n",
              "             'whence': 1,\n",
              "             'willingly': 2,\n",
              "             'came': 8,\n",
              "             'coronation': 1,\n",
              "             'must': 58,\n",
              "             'confesse': 5,\n",
              "             'thoughts': 17,\n",
              "             'wishes': 1,\n",
              "             'bend': 3,\n",
              "             'towards': 2,\n",
              "             'bow': 3,\n",
              "             'pardon': 8,\n",
              "             'fathers': 20,\n",
              "             'pollonius': 1,\n",
              "             'pol': 49,\n",
              "             'beseech': 8,\n",
              "             'go': 48,\n",
              "             'thine': 14,\n",
              "             'best': 11,\n",
              "             'graces': 2,\n",
              "             'spend': 1,\n",
              "             'cosin': 3,\n",
              "             'sonne': 20,\n",
              "             'ham': 337,\n",
              "             'little': 13,\n",
              "             'kin': 15,\n",
              "             'lesse': 7,\n",
              "             'kinde': 11,\n",
              "             'clouds': 3,\n",
              "             'still': 18,\n",
              "             'hang': 4,\n",
              "             \"i'th\": 20,\n",
              "             'sun': 3,\n",
              "             'queen': 8,\n",
              "             'colour': 4,\n",
              "             'off': 19,\n",
              "             'friend': 12,\n",
              "             'veyled': 1,\n",
              "             'lids': 1,\n",
              "             'seeke': 8,\n",
              "             'noble': 16,\n",
              "             'dust': 7,\n",
              "             \"know'st\": 2,\n",
              "             'common': 8,\n",
              "             'liues': 3,\n",
              "             'dye': 5,\n",
              "             'passing': 3,\n",
              "             'through': 7,\n",
              "             'eternity': 1,\n",
              "             'madam': 12,\n",
              "             'seemes': 8,\n",
              "             'tis': 12,\n",
              "             'alone': 10,\n",
              "             'inky': 1,\n",
              "             'cloake': 1,\n",
              "             'mother': 40,\n",
              "             'customary': 1,\n",
              "             'suites': 2,\n",
              "             'solemne': 2,\n",
              "             'blacke': 8,\n",
              "             'windy': 1,\n",
              "             'suspiration': 1,\n",
              "             'forc': 2,\n",
              "             'breath': 13,\n",
              "             'fruitfull': 1,\n",
              "             'riuer': 1,\n",
              "             'deiected': 1,\n",
              "             'hauiour': 1,\n",
              "             'visage': 5,\n",
              "             'formes': 3,\n",
              "             'moods': 1,\n",
              "             'shewes': 7,\n",
              "             'griefe': 2,\n",
              "             'denote': 1,\n",
              "             'truly': 5,\n",
              "             'indeed': 27,\n",
              "             'seeme': 9,\n",
              "             'actions': 1,\n",
              "             'man': 46,\n",
              "             'play': 40,\n",
              "             'within': 20,\n",
              "             'passeth': 1,\n",
              "             'show': 4,\n",
              "             'trappings': 1,\n",
              "             'sweet': 22,\n",
              "             'commendable': 1,\n",
              "             'mourning': 1,\n",
              "             'duties': 1,\n",
              "             'suruiuer': 1,\n",
              "             'bound': 5,\n",
              "             'filiall': 1,\n",
              "             'obligation': 2,\n",
              "             'terme': 2,\n",
              "             'obsequious': 1,\n",
              "             'perseuer': 1,\n",
              "             'obstinate': 1,\n",
              "             'condolement': 1,\n",
              "             'impious': 1,\n",
              "             'stubbornnesse': 1,\n",
              "             'vnmanly': 1,\n",
              "             'incorrect': 1,\n",
              "             'vnfortified': 1,\n",
              "             'minde': 10,\n",
              "             'impatient': 1,\n",
              "             'vnderstanding': 3,\n",
              "             'simple': 1,\n",
              "             'vnschool': 1,\n",
              "             'vulgar': 2,\n",
              "             'sence': 3,\n",
              "             'should': 54,\n",
              "             'peeuish': 1,\n",
              "             'opposition': 2,\n",
              "             'fye': 2,\n",
              "             'fault': 4,\n",
              "             'absurd': 2,\n",
              "             'theame': 2,\n",
              "             'cried': 2,\n",
              "             'first': 17,\n",
              "             'coarse': 3,\n",
              "             'till': 19,\n",
              "             'dyed': 3,\n",
              "             'throw': 4,\n",
              "             'vnpreuayling': 1,\n",
              "             'note': 6,\n",
              "             'immediate': 1,\n",
              "             'nobility': 1,\n",
              "             'loue': 65,\n",
              "             'deerest': 1,\n",
              "             'beares': 2,\n",
              "             'intent': 2,\n",
              "             'going': 2,\n",
              "             'backe': 6,\n",
              "             'schoole': 1,\n",
              "             'wittenberg': 3,\n",
              "             'retrograde': 1,\n",
              "             'desire': 7,\n",
              "             'remaine': 1,\n",
              "             'cheere': 2,\n",
              "             'comfort': 1,\n",
              "             'cheefest': 1,\n",
              "             'courtier': 3,\n",
              "             'qu': 62,\n",
              "             'lose': 4,\n",
              "             'her': 95,\n",
              "             'prayers': 1,\n",
              "             'prythee': 5,\n",
              "             'obey': 7,\n",
              "             'louing': 3,\n",
              "             'reply': 2,\n",
              "             'gentle': 4,\n",
              "             'vnforc': 1,\n",
              "             'accord': 1,\n",
              "             'sits': 4,\n",
              "             'smiling': 3,\n",
              "             'whereof': 2,\n",
              "             'iocond': 1,\n",
              "             'health': 5,\n",
              "             'drinkes': 2,\n",
              "             'great': 19,\n",
              "             'clowds': 1,\n",
              "             'kings': 8,\n",
              "             'rouce': 1,\n",
              "             'heauens': 10,\n",
              "             'bruite': 2,\n",
              "             'respeaking': 1,\n",
              "             'earthly': 1,\n",
              "             'thunder': 2,\n",
              "             'manet': 3,\n",
              "             'solid': 1,\n",
              "             'flesh': 5,\n",
              "             'melt': 2,\n",
              "             'thaw': 1,\n",
              "             'resolue': 1,\n",
              "             'into': 27,\n",
              "             'euerlasting': 1,\n",
              "             'fixt': 3,\n",
              "             'selfe-slaughter': 1,\n",
              "             'weary': 2,\n",
              "             'stale': 1,\n",
              "             'flat': 3,\n",
              "             'vnprofitable': 1,\n",
              "             'vses': 3,\n",
              "             'fie': 5,\n",
              "             'vnweeded': 1,\n",
              "             'garden': 2,\n",
              "             'growes': 4,\n",
              "             'seed': 1,\n",
              "             'rank': 1,\n",
              "             'possesse': 1,\n",
              "             'meerely': 2,\n",
              "             'months': 1,\n",
              "             'excellent': 11,\n",
              "             'hiperion': 1,\n",
              "             'satyre': 1,\n",
              "             'beteene': 1,\n",
              "             'windes': 2,\n",
              "             'visit': 4,\n",
              "             'face': 10,\n",
              "             'roughly': 2,\n",
              "             'remember': 12,\n",
              "             'she': 45,\n",
              "             'encrease': 1,\n",
              "             'appetite': 1,\n",
              "             'growne': 4,\n",
              "             'fed': 1,\n",
              "             'month': 2,\n",
              "             'frailty': 1,\n",
              "             'name': 10,\n",
              "             'woman': 7,\n",
              "             'ere': 15,\n",
              "             'shooes': 2,\n",
              "             'were': 26,\n",
              "             'followed': 2,\n",
              "             'poore': 20,\n",
              "             'body': 16,\n",
              "             'niobe': 1,\n",
              "             'teares': 8,\n",
              "             'beast': 5,\n",
              "             'wants': 2,\n",
              "             'discourse': 5,\n",
              "             'mourn': 1,\n",
              "             'longer': 5,\n",
              "             'married': 3,\n",
              "             'vnkle': 4,\n",
              "             'hercules': 3,\n",
              "             'moneth': 2,\n",
              "             'salt': 3,\n",
              "             'vnrighteous': 1,\n",
              "             'left': 4,\n",
              "             'flushing': 1,\n",
              "             'gauled': 1,\n",
              "             'wicked': 5,\n",
              "             'speed': 4,\n",
              "             'post': 1,\n",
              "             'dexterity': 1,\n",
              "             'incestuous': 4,\n",
              "             'sheets': 1,\n",
              "             'tongue': 14,\n",
              "             'haile': 1,\n",
              "             'lordship': 6,\n",
              "             'glad': 4,\n",
              "             'forget': 4,\n",
              "             'seruant': 1,\n",
              "             'change': 3,\n",
              "             'faith': 12,\n",
              "             'wittemberge': 1,\n",
              "             'truant': 2,\n",
              "             'disposition': 5,\n",
              "             'enemy': 2,\n",
              "             'doe': 51,\n",
              "             'eare': 17,\n",
              "             'truster': 1,\n",
              "             'report': 5,\n",
              "             'elsenour': 1,\n",
              "             \"wee'l\": 13,\n",
              "             'teach': 5,\n",
              "             'drinke': 14,\n",
              "             'deepe': 3,\n",
              "             'depart': 1,\n",
              "             'mock': 3,\n",
              "             'fellow': 9,\n",
              "             'student': 1,\n",
              "             'mothers': 6,\n",
              "             'wedding': 1,\n",
              "             'hard': 3,\n",
              "             'thrift': 4,\n",
              "             'bakt-meats': 1,\n",
              "             'coldly': 2,\n",
              "             'furnish': 1,\n",
              "             'forth': 5,\n",
              "             'tables': 3,\n",
              "             'met': 1,\n",
              "             'dearest': 1,\n",
              "             'foe': 2,\n",
              "             'thinkes': 5,\n",
              "             'minds': 2,\n",
              "             'saw': 13,\n",
              "             'goodly': 3,\n",
              "             'yesternight': 1,\n",
              "             'admiration': 3,\n",
              "             'while': 13,\n",
              "             'attent': 1,\n",
              "             'deliuer': 4,\n",
              "             'witnesse': 1,\n",
              "             'gentlemen': 12,\n",
              "             'maruell': 1,\n",
              "             'their': 48,\n",
              "             'wast': 1,\n",
              "             'middle': 2,\n",
              "             'beene': 13,\n",
              "             'encountred': 1,\n",
              "             'arm': 4,\n",
              "             'points': 2,\n",
              "             'exactly': 1,\n",
              "             'cap': 3,\n",
              "             'pe': 1,\n",
              "             'appeares': 3,\n",
              "             'sollemne': 1,\n",
              "             'slow': 2,\n",
              "             'stately': 1,\n",
              "             'thrice': 4,\n",
              "             'walkt': 1,\n",
              "             'opprest': 1,\n",
              "             'feare-surprized': 1,\n",
              "             'truncheons': 1,\n",
              "             'length': 4,\n",
              "             'whilst': 3,\n",
              "             \"bestil'd\": 1,\n",
              "             'almost': 7,\n",
              "             'ielly': 1,\n",
              "             'act': 9,\n",
              "             'feare': 20,\n",
              "             'dreadfull': 3,\n",
              "             'secrecie': 2,\n",
              "             'third': 3,\n",
              "             'kept': 4,\n",
              "             'whereas': 1,\n",
              "             'both': 34,\n",
              "             'each': 11,\n",
              "             'word': 11,\n",
              "             'knew': 4,\n",
              "             'hands': 9,\n",
              "             'platforme': 2,\n",
              "             'watcht': 1,\n",
              "             'answere': 4,\n",
              "             'none': 13,\n",
              "             'lifted': 1,\n",
              "             'addresse': 1,\n",
              "             'motion': 2,\n",
              "             'lowd': 2,\n",
              "             'shrunke': 1,\n",
              "             'vanisht': 1,\n",
              "             'honourd': 1,\n",
              "             'sirs': 3,\n",
              "             'troubles': 2,\n",
              "             'top': 8,\n",
              "             'toe': 2,\n",
              "             'foote': 3,\n",
              "             'yes': 5,\n",
              "             'wore': 1,\n",
              "             'beauer': 1,\n",
              "             'lookt': 2,\n",
              "             'frowningly': 1,\n",
              "             'countenance': 5,\n",
              "             'anger': 1,\n",
              "             'red': 2,\n",
              "             'constantly': 1,\n",
              "             'amaz': 1,\n",
              "             'staid': 3,\n",
              "             'moderate': 1,\n",
              "             'hundred': 2,\n",
              "             \"saw't\": 1,\n",
              "             'beard': 6,\n",
              "             'grisly': 1,\n",
              "             'sable': 2,\n",
              "             ...})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GPVTVDzDOTC"
      },
      "source": [
        "## Challenges / Limitations\n",
        "* Sparsity of BOW\n",
        "* Lost information of text order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wCYMqhgT9lc"
      },
      "source": [
        "# Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JtzWJoXOQ2D"
      },
      "source": [
        "## Cosine Similarity\n",
        "\n",
        "![](https://neo4j.com/docs/graph-data-science/current/_images/cosine-similarity.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXk8GFNDOUcf",
        "outputId": "bb094893-3a13-4317-8749-4892517aa206"
      },
      "source": [
        "# Cosine similarity of OHE vectors is 0 if different, 1 if same\n",
        "X = [1, 0]\n",
        "Y = [0, 1]\n",
        "cos = 1 - cosine(X, Y)\n",
        "cos"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yUhEZUGQ_z2",
        "outputId": "dd916a25-f35b-48b0-b649-e20899ed26eb"
      },
      "source": [
        "# Cosine similarity is unaffected by magnitude (TF)\n",
        "X = [.5, .5]\n",
        "Y1 = [5, 5]\n",
        "Y2 = [50, 50]\n",
        "cos1 = 1 - cosine(X, Y1)\n",
        "cos2 = 1 - cosine(X, Y2)\n",
        "cos1, cos2"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPxaP0cITJl5",
        "outputId": "8109869d-3269-4d7a-b33f-08e5a6dec576"
      },
      "source": [
        "# Minimum similarity is -1 if vectors are opposite\n",
        "X = [1, 1]\n",
        "Y = [-1, -1]\n",
        "cos = 1 - cosine(X, Y)\n",
        "cos"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFlZEq1WPkdS",
        "outputId": "31d2c8a3-3e12-4139-b3e2-38f03235c284"
      },
      "source": [
        "# Cosine Similarity can run in multiple dimensions\n",
        "X = [1, 2, 3, 4, 5]\n",
        "Y = [5, 4, 3, 2, 1]\n",
        "cos = 1 - cosine(X, Y)\n",
        "cos"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6363636363636364"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9PWe0UTUC6z"
      },
      "source": [
        "## Euclidean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxP5BK-OU26D",
        "outputId": "5a85c185-58c2-47d5-8c17-2eac51ddc065"
      },
      "source": [
        "# Euclidean distance the same for OHE vectors = Sqrt(2)\n",
        "X = [1, 0]\n",
        "Y = [0, 1]\n",
        "euc = euclidean(X, Y)\n",
        "euc"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4142135623730951"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OiL261rVPTa",
        "outputId": "855c6be5-5873-4d1b-d158-7beccb91bdb8"
      },
      "source": [
        "# Euclidean distance is affected by magnitude (TF)\n",
        "X = [.5, .5]\n",
        "Y1 = [5, 5]\n",
        "Y2 = [50, 50]\n",
        "euc1 = euclidean(X, Y1)\n",
        "euc2 = euclidean(X, Y2)\n",
        "euc1, euc2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.363961030678928, 70.0035713374682)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fGNUmFqV3na"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "86sPmqBjV2jz",
        "outputId": "99650f36-8f28-4f00-f9a9-9b0cf0b29c5e"
      },
      "source": [
        "X = [1, 1]\n",
        "Y = [0, .75]\n",
        "Z = [5, 5]\n",
        "\n",
        "plt.scatter(X[0], X[1])\n",
        "plt.scatter(Y[0], Y[1])\n",
        "plt.scatter(Z[0], Z[1])\n",
        "\n",
        "plt.plot([0, X[0]], [0, X[1]])\n",
        "plt.plot([0, Y[0]], [0, Y[1]])\n",
        "plt.plot([0, Z[0]], [0, Z[1]], linestyle='--')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff0056cb890>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSU29aXlWtJM",
        "outputId": "cd11dcfa-ee62-41c6-d3ff-201f548b01e1"
      },
      "source": [
        " print('X Compared to Y')\n",
        "print(X, Y)\n",
        "print('Euclidean', euclidean(X, Y))\n",
        "print('Cosine', 1 - cosine(X, Y))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Compared to Y\n",
            "[1, 1] [0, 0.75]\n",
            "Euclidean 1.0307764064044151\n",
            "Cosine 0.7071067811865476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e33Gq-6cWI4X",
        "outputId": "829f4f0a-1a04-46fd-80a2-b57e85d97ede"
      },
      "source": [
        "print('X Compared to Z')\n",
        "print(X, Z)\n",
        "print('Euclidean', euclidean(X, Z))\n",
        "print('Cosine', 1 - cosine(X, Z))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Compared to Z\n",
            "[1, 1] [5, 5]\n",
            "Euclidean 5.656854249492381\n",
            "Cosine 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3aMSgNnXEIH"
      },
      "source": [
        "* X to Y has lower euclidean distance\n",
        "* X to Y has lower cosine similarity\n",
        "* What leads to higher \"magnitudes\" in text?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcCMCR5la2jO"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN-qMeTDbUh7"
      },
      "source": [
        "texts = ['shakespeare-hamlet.txt',\n",
        "         'shakespeare-macbeth.txt',\n",
        "         'melville-moby_dick.txt',\n",
        "         'milton-paradise.txt']\n",
        "\n",
        "raw = [gutenberg.raw(t) for t in texts]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA8EUDuzjYxd",
        "outputId": "ffd5e064-61f7-47f2-fe09-bc7160aa8a63"
      },
      "source": [
        "# Fit\n",
        "cv = CountVectorizer()\n",
        "cv.fit(raw)\n",
        "len(cv.get_feature_names())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24182"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuCuF4ZliCqO"
      },
      "source": [
        "# Transform\n",
        "vectorized = cv.transform(raw)\n",
        "bow = vectorized.toarray()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzXPIwiuh3Gh",
        "outputId": "45b1cb65-e4b7-4ff6-b56d-3d8fa20c3598"
      },
      "source": [
        "# Each document has the same size = vocab\n",
        "[len(doc) for doc in bow]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24182, 24182, 24182, 24182]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U03vUx2CiHEi",
        "outputId": "d08e5566-3d3a-46aa-e349-160568f785c6"
      },
      "source": [
        "# How many unique words are there in each\n",
        "np.count_nonzero(bow, axis=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4688,  3436, 17110,  8971])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t6aYRVIkMpt",
        "outputId": "b7fc2c2f-0611-4da2-d164-6c357929111a"
      },
      "source": [
        "# Top word \n",
        "top = np.argmax(bow, axis=1)\n",
        "[cv.get_feature_names()[i] for i in top]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'the', 'the', 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1-vmTutbyDb"
      },
      "source": [
        "# Is Hamlet more of a Melville or a Milton?\n",
        "shake_hamlet, shake_macbeth, melville, milton = bow.squeeze()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YqJSx3UcYs5",
        "outputId": "96aeb717-7e84-4145-f6e4-b7ec6e51e1d4"
      },
      "source": [
        "# Euclidean\n",
        "# Shakespeare - Shakespeare close\n",
        "# Hamlet is more Milton (least distance)\n",
        "ham_to_macbeth  = euclidean(shake_hamlet, shake_macbeth)\n",
        "ham_to_melville = euclidean(shake_hamlet, melville)\n",
        "ham_to_milton   = euclidean(shake_hamlet, milton)\n",
        "print(ham_to_macbeth, ham_to_melville, ham_to_milton)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1142.7458160063418 18487.17893568405 4808.8941556245545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL2tfQuYdBrF",
        "outputId": "29c98b7a-0edf-4b4d-a1db-2013945acaf7"
      },
      "source": [
        "# Cosine Similarity\n",
        "# Shakespeare - Shakespeare close\n",
        "# Barely, Hamlet is more Milton (highest similarity)\n",
        "ham_to_macbeth  = 1 - cosine(shake_hamlet, shake_macbeth)\n",
        "ham_to_melville = 1 - cosine(shake_hamlet, melville)\n",
        "ham_to_milton   = 1 - cosine(shake_hamlet, milton)\n",
        "print(ham_to_macbeth, ham_to_melville, ham_to_milton)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9462232228410759 0.8418050311907488 0.8426230205421135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J37cmJLjuClU",
        "outputId": "24523bb6-f67a-4691-836c-849e884a3e1a"
      },
      "source": [
        "# Top 10 Words - Something Foul - These words aren't very discriminitive\n",
        "ind = np.argpartition(bow, -10, axis=1)\n",
        "top = [row[-10:] for row in ind]\n",
        "[cv.get_feature_names()[i] for row in top for i in row]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ham',\n",
              " 'that',\n",
              " 'in',\n",
              " 'my',\n",
              " 'the',\n",
              " 'you',\n",
              " 'it',\n",
              " 'to',\n",
              " 'and',\n",
              " 'of',\n",
              " 'not',\n",
              " 'is',\n",
              " 'in',\n",
              " 'my',\n",
              " 'you',\n",
              " 'that',\n",
              " 'to',\n",
              " 'the',\n",
              " 'and',\n",
              " 'of',\n",
              " 'but',\n",
              " 'he',\n",
              " 'it',\n",
              " 'his',\n",
              " 'to',\n",
              " 'that',\n",
              " 'in',\n",
              " 'and',\n",
              " 'the',\n",
              " 'of',\n",
              " 'all',\n",
              " 'that',\n",
              " 'or',\n",
              " 'with',\n",
              " 'his',\n",
              " 'in',\n",
              " 'the',\n",
              " 'and',\n",
              " 'to',\n",
              " 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSdzjSUTXx4-"
      },
      "source": [
        "# Preprocessing\n",
        "* Common transformations to improve the bag of words\n",
        "* This helps \"normalize\" the data\n",
        "* But we again, will be losing information\n",
        "* To illustrate, we'll use build on CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX1qZCJxYlrm"
      },
      "source": [
        "## Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDbtV9KXYodH"
      },
      "source": [
        "# Count vectorizer applies lower casing to True by default\n",
        "count_vec = CountVectorizer(lowercase=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRgP97miX6Jx"
      },
      "source": [
        "## Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJQyRBwiaN8u",
        "outputId": "1f9f9070-bbe8-4c49-b57e-1153441b2af0"
      },
      "source": [
        "# Count vectorizer applies a regular expression around words \n",
        "# This eliminates punctuation r(?u)\\b\\w\\w+\\b\n",
        "# How could we include punctuation or adjust this?\n",
        "count_vec = CountVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\")\n",
        "bow = count_vec.fit_transform([hamlet_raw])\n",
        "print(f'There are {len(count_vec.get_feature_names()):,} unique tokens in Hamlet')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4,691 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "_B1TnlNRbR7W",
        "outputId": "2807d522-084f-439f-be0c-87721f8c0e39"
      },
      "source": [
        "df = pd.DataFrame(bow.toarray(), columns=count_vec.get_feature_names())\n",
        "df"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>!</th>\n",
              "      <th>'</th>\n",
              "      <th>1599</th>\n",
              "      <th>?</th>\n",
              "      <th>abhominably</th>\n",
              "      <th>abhorred</th>\n",
              "      <th>abilitie</th>\n",
              "      <th>aboord</th>\n",
              "      <th>aboue</th>\n",
              "      <th>about</th>\n",
              "      <th>abridgements</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolute</th>\n",
              "      <th>abstinence</th>\n",
              "      <th>abstracts</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abus</th>\n",
              "      <th>abuse</th>\n",
              "      <th>abuses</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepts</th>\n",
              "      <th>accesse</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentall</th>\n",
              "      <th>accord</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accounted</th>\n",
              "      <th>accurst</th>\n",
              "      <th>accuse</th>\n",
              "      <th>acquaint</th>\n",
              "      <th>acquire</th>\n",
              "      <th>acquittance</th>\n",
              "      <th>act</th>\n",
              "      <th>acte</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>actions</th>\n",
              "      <th>...</th>\n",
              "      <th>wrights</th>\n",
              "      <th>wring</th>\n",
              "      <th>wringing</th>\n",
              "      <th>wrinkled</th>\n",
              "      <th>wrist</th>\n",
              "      <th>writ</th>\n",
              "      <th>write</th>\n",
              "      <th>writers</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wrought</th>\n",
              "      <th>yases</th>\n",
              "      <th>yaughan</th>\n",
              "      <th>yawne</th>\n",
              "      <th>ye</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeare</th>\n",
              "      <th>yeares</th>\n",
              "      <th>years</th>\n",
              "      <th>yeeld</th>\n",
              "      <th>yeelding</th>\n",
              "      <th>yeomans</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yesternight</th>\n",
              "      <th>yesty</th>\n",
              "      <th>yet</th>\n",
              "      <th>yon</th>\n",
              "      <th>yond</th>\n",
              "      <th>yonder</th>\n",
              "      <th>yong</th>\n",
              "      <th>yonger</th>\n",
              "      <th>yorick</th>\n",
              "      <th>yoricks</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>youth</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>729</td>\n",
              "      <td>1</td>\n",
              "      <td>459</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>527</td>\n",
              "      <td>9</td>\n",
              "      <td>253</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows  4691 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    !    '  1599    ?  abhominably  ...  young  your  yours  youth  zone\n",
              "0  17  729     1  459            1  ...      9   253      6     14     1\n",
              "\n",
              "[1 rows x 4691 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "a7ZTjuVFbM-B",
        "outputId": "f6b45702-bfaf-45ad-a773-ebefbfe2cd97"
      },
      "source": [
        "# Top 10 words - With punctuation\n",
        "top = np.argsort(-df.values, axis=1)[:, : 10]\n",
        "result = pd.DataFrame(df.columns[top], index=df.index)\n",
        "result"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the</td>\n",
              "      <td>and</td>\n",
              "      <td>'</td>\n",
              "      <td>to</td>\n",
              "      <td>of</td>\n",
              "      <td>you</td>\n",
              "      <td>my</td>\n",
              "      <td>?</td>\n",
              "      <td>it</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1  2   3   4    5   6  7   8   9\n",
              "0  the  and  '  to  of  you  my  ?  it  in"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSzqJ4nsu7oy"
      },
      "source": [
        "## Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1Gmamph26Lw",
        "outputId": "c02c9052-05b7-4009-dba2-a34bb4e8ef1c"
      },
      "source": [
        "# Bag of words for Hamlet\n",
        "count_vec = CountVectorizer()\n",
        "bow = count_vec.fit_transform([hamlet_raw])\n",
        "print(f'There are {len(count_vec.get_feature_names()):,} unique tokens in Hamlet')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4,688 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "rCP5GQmJU3O5",
        "outputId": "82b3486b-5d07-4aec-f76f-b9840497e8e2"
      },
      "source": [
        "# To a DataFrame\n",
        "df = pd.DataFrame(bow.toarray(), columns=count_vec.get_feature_names())\n",
        "df"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1599</th>\n",
              "      <th>abhominably</th>\n",
              "      <th>abhorred</th>\n",
              "      <th>abilitie</th>\n",
              "      <th>aboord</th>\n",
              "      <th>aboue</th>\n",
              "      <th>about</th>\n",
              "      <th>abridgements</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolute</th>\n",
              "      <th>abstinence</th>\n",
              "      <th>abstracts</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abus</th>\n",
              "      <th>abuse</th>\n",
              "      <th>abuses</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepts</th>\n",
              "      <th>accesse</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentall</th>\n",
              "      <th>accord</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accounted</th>\n",
              "      <th>accurst</th>\n",
              "      <th>accuse</th>\n",
              "      <th>acquaint</th>\n",
              "      <th>acquire</th>\n",
              "      <th>acquittance</th>\n",
              "      <th>act</th>\n",
              "      <th>acte</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>actions</th>\n",
              "      <th>actiuely</th>\n",
              "      <th>actor</th>\n",
              "      <th>actors</th>\n",
              "      <th>...</th>\n",
              "      <th>wrights</th>\n",
              "      <th>wring</th>\n",
              "      <th>wringing</th>\n",
              "      <th>wrinkled</th>\n",
              "      <th>wrist</th>\n",
              "      <th>writ</th>\n",
              "      <th>write</th>\n",
              "      <th>writers</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wrought</th>\n",
              "      <th>yases</th>\n",
              "      <th>yaughan</th>\n",
              "      <th>yawne</th>\n",
              "      <th>ye</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeare</th>\n",
              "      <th>yeares</th>\n",
              "      <th>years</th>\n",
              "      <th>yeeld</th>\n",
              "      <th>yeelding</th>\n",
              "      <th>yeomans</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yesternight</th>\n",
              "      <th>yesty</th>\n",
              "      <th>yet</th>\n",
              "      <th>yon</th>\n",
              "      <th>yond</th>\n",
              "      <th>yonder</th>\n",
              "      <th>yong</th>\n",
              "      <th>yonger</th>\n",
              "      <th>yorick</th>\n",
              "      <th>yoricks</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>youth</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>527</td>\n",
              "      <td>9</td>\n",
              "      <td>253</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows  4688 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1599  abhominably  abhorred  abilitie  ...  your  yours  youth  zone\n",
              "0     1            1         1         1  ...   253      6     14     1\n",
              "\n",
              "[1 rows x 4688 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "yFsPiAHUV_zr",
        "outputId": "cf2be0a1-c9f5-4747-9d81-cf2a66434e28"
      },
      "source": [
        "# Top 10 words\n",
        "top = np.argsort(-df.values, axis=1)[:, : 10]\n",
        "result = pd.DataFrame(df.columns[top], index=df.index)\n",
        "result"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the</td>\n",
              "      <td>and</td>\n",
              "      <td>to</td>\n",
              "      <td>of</td>\n",
              "      <td>you</td>\n",
              "      <td>my</td>\n",
              "      <td>it</td>\n",
              "      <td>in</td>\n",
              "      <td>that</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1   2   3    4   5   6   7     8    9\n",
              "0  the  and  to  of  you  my  it  in  that  ham"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmAYebqtT6Pp",
        "outputId": "5198b1ce-c704-4a47-d181-d1317d517d3e"
      },
      "source": [
        "# Apply stop words\n",
        "stop = set(stopwords.words('english'))\n",
        "count_vec = CountVectorizer(stop_words=stop)\n",
        "bow_stop = count_vec.fit_transform([hamlet_raw])\n",
        "print(f'There are {len(count_vec.get_feature_names()):,} unique tokens in Hamlet')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4,587 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "DR5XT7N6XcYR",
        "outputId": "5b292a73-40b7-44c5-e694-bdf1354a6f66"
      },
      "source": [
        "# To a DataFrame\n",
        "df = pd.DataFrame(bow_stop.toarray(), columns=count_vec.get_feature_names())\n",
        "df"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1599</th>\n",
              "      <th>abhominably</th>\n",
              "      <th>abhorred</th>\n",
              "      <th>abilitie</th>\n",
              "      <th>aboord</th>\n",
              "      <th>aboue</th>\n",
              "      <th>abridgements</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolute</th>\n",
              "      <th>abstinence</th>\n",
              "      <th>abstracts</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abus</th>\n",
              "      <th>abuse</th>\n",
              "      <th>abuses</th>\n",
              "      <th>accent</th>\n",
              "      <th>accepts</th>\n",
              "      <th>accesse</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentall</th>\n",
              "      <th>accord</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accounted</th>\n",
              "      <th>accurst</th>\n",
              "      <th>accuse</th>\n",
              "      <th>acquaint</th>\n",
              "      <th>acquire</th>\n",
              "      <th>acquittance</th>\n",
              "      <th>act</th>\n",
              "      <th>acte</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>actions</th>\n",
              "      <th>actiuely</th>\n",
              "      <th>actor</th>\n",
              "      <th>actors</th>\n",
              "      <th>acts</th>\n",
              "      <th>...</th>\n",
              "      <th>wrath</th>\n",
              "      <th>wretch</th>\n",
              "      <th>wretched</th>\n",
              "      <th>wrights</th>\n",
              "      <th>wring</th>\n",
              "      <th>wringing</th>\n",
              "      <th>wrinkled</th>\n",
              "      <th>wrist</th>\n",
              "      <th>writ</th>\n",
              "      <th>write</th>\n",
              "      <th>writers</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wrought</th>\n",
              "      <th>yases</th>\n",
              "      <th>yaughan</th>\n",
              "      <th>yawne</th>\n",
              "      <th>ye</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeare</th>\n",
              "      <th>yeares</th>\n",
              "      <th>years</th>\n",
              "      <th>yeeld</th>\n",
              "      <th>yeelding</th>\n",
              "      <th>yeomans</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yesternight</th>\n",
              "      <th>yesty</th>\n",
              "      <th>yet</th>\n",
              "      <th>yon</th>\n",
              "      <th>yond</th>\n",
              "      <th>yonder</th>\n",
              "      <th>yong</th>\n",
              "      <th>yonger</th>\n",
              "      <th>yorick</th>\n",
              "      <th>yoricks</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows  4587 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1599  abhominably  abhorred  abilitie  ...  yoricks  young  youth  zone\n",
              "0     1            1         1         1  ...        1      9     14     1\n",
              "\n",
              "[1 rows x 4587 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "ZNhTXTQ8XcfF",
        "outputId": "1073054e-b63b-49c5-d014-a57190e12f94"
      },
      "source": [
        "# Top 10 words\n",
        "top = np.argsort(-df.values, axis=1)[:, : 10]\n",
        "result = pd.DataFrame(df.columns[top], index=df.index)\n",
        "result"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>lord</td>\n",
              "      <td>haue</td>\n",
              "      <td>king</td>\n",
              "      <td>shall</td>\n",
              "      <td>thou</td>\n",
              "      <td>come</td>\n",
              "      <td>let</td>\n",
              "      <td>hamlet</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1     2     3      4     5     6    7       8     9\n",
              "0  ham  lord  haue  king  shall  thou  come  let  hamlet  good"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSlrdM9qZNG9"
      },
      "source": [
        "## Stemming\n",
        "* Similar meaning different tokens\n",
        "  * Happy and Happier\n",
        "  * Run and Runs\n",
        "  * Think cosine difference!\n",
        "* With preprocessing and bag of words we have to adjust the text\n",
        "* PorterStemmer is a popular approach\n",
        "  * Works on the English Language\n",
        "  * https://vijinimallawaarachchi.com/2017/05/09/porter-stemming-algorithm/\n",
        "* Stemming isn't directly supported in CountVectorizer\n",
        "* We can override the analyzer (specifically, we build one that stems)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wTWcGJ0cBvo"
      },
      "source": [
        "porter_stemmer = nltk.stem.PorterStemmer()\n",
        "class PorterCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(PorterCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([porter_stemmer.stem(w) for w in analyzer(doc)])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME9zkCU3cz9Z",
        "outputId": "704852b4-2dea-4754-e66d-6071a612a9ae"
      },
      "source": [
        "# Note:  We normally see 4,688 tokens\n",
        "count_vec = PorterCountVectorizer()\n",
        "bow_stem = count_vec.fit_transform([hamlet_raw])\n",
        "print(f'There are {len(count_vec.get_feature_names()):,} unique tokens in Hamlet')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3,732 unique tokens in Hamlet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "bLSAenwOdASt",
        "outputId": "bce43c4c-ba17-4139-87aa-96da2ca0ad58"
      },
      "source": [
        "# To a DataFrame\n",
        "df = pd.DataFrame(bow_stem.toarray(), columns=count_vec.get_feature_names())\n",
        "df"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1599</th>\n",
              "      <th>abhomin</th>\n",
              "      <th>abhor</th>\n",
              "      <th>abiliti</th>\n",
              "      <th>aboord</th>\n",
              "      <th>abou</th>\n",
              "      <th>about</th>\n",
              "      <th>abridg</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absent</th>\n",
              "      <th>absolut</th>\n",
              "      <th>abstin</th>\n",
              "      <th>abstract</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abu</th>\n",
              "      <th>abus</th>\n",
              "      <th>accent</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accid</th>\n",
              "      <th>accidental</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>accurst</th>\n",
              "      <th>accus</th>\n",
              "      <th>acquaint</th>\n",
              "      <th>acquir</th>\n",
              "      <th>acquitt</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actiu</th>\n",
              "      <th>actor</th>\n",
              "      <th>actu</th>\n",
              "      <th>adai</th>\n",
              "      <th>adam</th>\n",
              "      <th>addict</th>\n",
              "      <th>addit</th>\n",
              "      <th>address</th>\n",
              "      <th>adher</th>\n",
              "      <th>adieu</th>\n",
              "      <th>...</th>\n",
              "      <th>wot</th>\n",
              "      <th>would</th>\n",
              "      <th>wouldest</th>\n",
              "      <th>wound</th>\n",
              "      <th>wrack</th>\n",
              "      <th>wrath</th>\n",
              "      <th>wretch</th>\n",
              "      <th>wright</th>\n",
              "      <th>wring</th>\n",
              "      <th>wrinkl</th>\n",
              "      <th>wrist</th>\n",
              "      <th>writ</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wrought</th>\n",
              "      <th>yase</th>\n",
              "      <th>yaughan</th>\n",
              "      <th>yawn</th>\n",
              "      <th>ye</th>\n",
              "      <th>yea</th>\n",
              "      <th>year</th>\n",
              "      <th>yeeld</th>\n",
              "      <th>yeoman</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yesternight</th>\n",
              "      <th>yesti</th>\n",
              "      <th>yet</th>\n",
              "      <th>yon</th>\n",
              "      <th>yond</th>\n",
              "      <th>yonder</th>\n",
              "      <th>yong</th>\n",
              "      <th>yonger</th>\n",
              "      <th>yorick</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>youth</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>527</td>\n",
              "      <td>9</td>\n",
              "      <td>259</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows  3732 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1599  abhomin  abhor  abiliti  aboord  ...  you  young  your  youth  zone\n",
              "0     1        1      1        1       3  ...  527      9   259     14     1\n",
              "\n",
              "[1 rows x 3732 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "gsbTVqj_dwsu",
        "outputId": "baf83370-1733-4f19-a79a-492ec31afb67"
      },
      "source": [
        "# Example words (Notice: nois, fals, loos, morn)\n",
        "top = np.argsort(-df.values, axis=1)[:, 500 : 520]\n",
        "result = pd.DataFrame(df.columns[top], index=df.index)\n",
        "result"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mouth</td>\n",
              "      <td>morn</td>\n",
              "      <td>shame</td>\n",
              "      <td>sorrow</td>\n",
              "      <td>nois</td>\n",
              "      <td>bad</td>\n",
              "      <td>fals</td>\n",
              "      <td>sure</td>\n",
              "      <td>loos</td>\n",
              "      <td>crown</td>\n",
              "      <td>ill</td>\n",
              "      <td>bar</td>\n",
              "      <td>list</td>\n",
              "      <td>beard</td>\n",
              "      <td>lack</td>\n",
              "      <td>distract</td>\n",
              "      <td>beast</td>\n",
              "      <td>gaue</td>\n",
              "      <td>wretch</td>\n",
              "      <td>prison</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1      2       3     4   ...        15     16    17      18      19\n",
              "0  mouth  morn  shame  sorrow  nois  ...  distract  beast  gaue  wretch  prison\n",
              "\n",
              "[1 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq7ReTGGtU-7"
      },
      "source": [
        "# TF-IDF\n",
        "![](https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dx7Tdvm13TD"
      },
      "source": [
        "## Intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQXt_CdTpXR3",
        "outputId": "13cfc79f-2c9f-4f94-be12-94938fdcb286"
      },
      "source": [
        "# 100 words in document - regression appears 5 times\n",
        "tf = 5 / 100\n",
        "tf"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYaL8xw9ps_l",
        "outputId": "8848af8e-3cc7-4843-c035-141dbfa624bd"
      },
      "source": [
        "# 100 documents - regression appears 10 times\n",
        "idf = np.log(100 / 5)\n",
        "idf"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.995732273553991"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3SfVWy8p3oP",
        "outputId": "6fb1bcae-4df5-42b2-9bd2-e3e032f0425b"
      },
      "source": [
        "# For the word regression\n",
        "tfidf = tf * idf\n",
        "tfidf"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14978661367769955"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0KoCNWUqBvK",
        "outputId": "3d817c2d-e843-4005-f759-fd0f5eae51b6"
      },
      "source": [
        "# How does a word's value vary?\n",
        "# What if regression appeared 10 times instead of 5?\n",
        "# More frequently appearing words have higher scores\n",
        "tf = 10 / 100\n",
        "idf = np.log(100 / 5)\n",
        "tfidf = tf * idf\n",
        "tfidf"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2995732273553991"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai6BJi9VqRDR",
        "outputId": "b47ad4e8-662a-4562-fab4-83bfb9bc42c1"
      },
      "source": [
        "# How does a word's value vary?\n",
        "# What if regression appeared 2 times instead of 5?\n",
        "# More remote words have higher scores\n",
        "tf = 5 / 100\n",
        "idf = np.log(100 / 2)\n",
        "tfidf = tf * idf\n",
        "tfidf"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19560115027140731"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neUpAi78qiBG",
        "outputId": "427b0d18-b458-4157-eec2-0322ba45170b"
      },
      "source": [
        "# How does a word's value vary?\n",
        "# What if regression appeared 20 times instead of 5?\n",
        "# More remote words have higher scores\n",
        "tf = 5 / 100\n",
        "idf = np.log(100 / 29)\n",
        "tfidf = tf * idf\n",
        "tfidf"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.061893717800080864"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSqjSNqM10mT"
      },
      "source": [
        "## TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9L3PMFmhOyA"
      },
      "source": [
        "texts = ['shakespeare-hamlet.txt',\n",
        "         'shakespeare-macbeth.txt',\n",
        "         'melville-moby_dick.txt',\n",
        "         'milton-paradise.txt']\n",
        "\n",
        "raw = [gutenberg.raw(t) for t in texts]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi8YMA_cur5X",
        "outputId": "5b1cfd66-51dd-4bd4-da5d-dbb5e1643d3f"
      },
      "source": [
        "# Fit\n",
        "tv = TfidfVectorizer()\n",
        "vectorized = tv.fit_transform(raw)\n",
        "tfidf_bow = vectorized.toarray()\n",
        "len(tv.get_feature_names())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24182"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "j5Yku_HZhBPU",
        "outputId": "56a5fa1a-90a6-4c88-a616-96ba4d503d47"
      },
      "source": [
        "# View documents in frame\n",
        "df = pd.DataFrame(tfidf_bow, columns=tv.get_feature_names())\n",
        "df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>00021053</th>\n",
              "      <th>00081429</th>\n",
              "      <th>00482129</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>13</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>...</th>\n",
              "      <th>yore</th>\n",
              "      <th>yorick</th>\n",
              "      <th>yoricks</th>\n",
              "      <th>york</th>\n",
              "      <th>yorkshire</th>\n",
              "      <th>you</th>\n",
              "      <th>youl</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngest</th>\n",
              "      <th>youngish</th>\n",
              "      <th>your</th>\n",
              "      <th>yours</th>\n",
              "      <th>yourselbs</th>\n",
              "      <th>yourself</th>\n",
              "      <th>yourselves</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>youths</th>\n",
              "      <th>zag</th>\n",
              "      <th>zay</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealanders</th>\n",
              "      <th>zealous</th>\n",
              "      <th>zenith</th>\n",
              "      <th>zephon</th>\n",
              "      <th>zephyr</th>\n",
              "      <th>zephyrus</th>\n",
              "      <th>zeuglodon</th>\n",
              "      <th>zig</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zodiack</th>\n",
              "      <th>zogranda</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoned</th>\n",
              "      <th>zones</th>\n",
              "      <th>zoology</th>\n",
              "      <th>zophiel</th>\n",
              "      <th>zoroaster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000801</td>\n",
              "      <td>0.000801</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220310</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105766</td>\n",
              "      <td>0.002508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005853</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149303</td>\n",
              "      <td>0.001389</td>\n",
              "      <td>0.002899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091321</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001389</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.043367</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003881</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.012079</td>\n",
              "      <td>0.000437</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.002417</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>0.000437</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000651</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000451</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007966</td>\n",
              "      <td>0.000751</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.001052</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002271</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows  24182 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        000  00021053  00081429  ...   zoology   zophiel  zoroaster\n",
              "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000   0.000000\n",
              "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000   0.000000\n",
              "2  0.001859  0.000000  0.000000  ...  0.000186  0.000000   0.000093\n",
              "3  0.000000  0.000288  0.000288  ...  0.000000  0.000288   0.000000\n",
              "\n",
              "[4 rows x 24182 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meUm8OLNu2a-",
        "outputId": "b4e283ab-9d03-4470-e829-d9b5d7b8559c"
      },
      "source": [
        "# Top 10 Words - Not much different - although there is a ham, macb & whale\n",
        "ind = np.argpartition(tfidf_bow, -10, axis=1)\n",
        "top = [row[-10:] for row in ind]\n",
        "[tv.get_feature_names()[i] for row in top for i in row]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['that',\n",
              " 'in',\n",
              " 'it',\n",
              " 'my',\n",
              " 'you',\n",
              " 'the',\n",
              " 'ham',\n",
              " 'of',\n",
              " 'and',\n",
              " 'to',\n",
              " 'is',\n",
              " 'in',\n",
              " 'to',\n",
              " 'my',\n",
              " 'and',\n",
              " 'you',\n",
              " 'of',\n",
              " 'the',\n",
              " 'that',\n",
              " 'macb',\n",
              " 'whale',\n",
              " 'he',\n",
              " 'and',\n",
              " 'it',\n",
              " 'in',\n",
              " 'to',\n",
              " 'the',\n",
              " 'that',\n",
              " 'of',\n",
              " 'his',\n",
              " 'all',\n",
              " 'that',\n",
              " 'or',\n",
              " 'with',\n",
              " 'to',\n",
              " 'his',\n",
              " 'of',\n",
              " 'in',\n",
              " 'the',\n",
              " 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Vs4w5EfkfJ"
      },
      "source": [
        "# Is Hamlet more of a Melville or a Milton?\n",
        "shake_hamlet, shake_macbeth, melville, milton = tfidf_bow.squeeze()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33fAggDkf49A",
        "outputId": "14bd8a5f-e124-45aa-fe85-166989e6f63b"
      },
      "source": [
        "# Cosine Similarity\n",
        "# Shakespeare - Shakespeare close\n",
        "# Barely, Hamlet is more Milton (highest similarity)\n",
        "ham_to_macbeth  = 1 - cosine(shake_hamlet, shake_macbeth)\n",
        "ham_to_melville = 1 - cosine(shake_hamlet, melville)\n",
        "ham_to_milton   = 1 - cosine(shake_hamlet, milton)\n",
        "print(ham_to_macbeth, ham_to_melville, ham_to_milton)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8975147884285783 0.8045713048108598 0.8064285666527298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxeKRC0ef_zN"
      },
      "source": [
        "## Tfidf Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hoyNv-BgHR4"
      },
      "source": [
        "texts = ['shakespeare-hamlet.txt',\n",
        "         'shakespeare-macbeth.txt',\n",
        "         'melville-moby_dick.txt',\n",
        "         'milton-paradise.txt']\n",
        "\n",
        "raw = [gutenberg.raw(t) for t in texts]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4NO9eoOgNZM"
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "pcv = PorterCountVectorizer(stop_words=stop)\n",
        "bow = pcv.fit_transform(raw)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghEqmpDmghvZ"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "vectorized = tfidf_transformer.fit_transform(bow)\n",
        "tfidf_bow = vectorized.toarray()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "saWYH3HlgKkb",
        "outputId": "b369984d-6554-4025-bb89-2ea7907167fe"
      },
      "source": [
        "df = pd.DataFrame(tfidf_bow, columns=pcv.get_feature_names())\n",
        "df"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>00021053</th>\n",
              "      <th>00081429</th>\n",
              "      <th>00482129</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>13</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>...</th>\n",
              "      <th>yew</th>\n",
              "      <th>yield</th>\n",
              "      <th>ynch</th>\n",
              "      <th>yoak</th>\n",
              "      <th>yojo</th>\n",
              "      <th>yoke</th>\n",
              "      <th>yon</th>\n",
              "      <th>yond</th>\n",
              "      <th>yonder</th>\n",
              "      <th>yong</th>\n",
              "      <th>yonger</th>\n",
              "      <th>yore</th>\n",
              "      <th>yorick</th>\n",
              "      <th>york</th>\n",
              "      <th>yorkshir</th>\n",
              "      <th>youl</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngest</th>\n",
              "      <th>youngish</th>\n",
              "      <th>yourselb</th>\n",
              "      <th>youth</th>\n",
              "      <th>zag</th>\n",
              "      <th>zay</th>\n",
              "      <th>zeal</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealou</th>\n",
              "      <th>zenith</th>\n",
              "      <th>zephon</th>\n",
              "      <th>zephyr</th>\n",
              "      <th>zephyru</th>\n",
              "      <th>zeuglodon</th>\n",
              "      <th>zig</th>\n",
              "      <th>zodiac</th>\n",
              "      <th>zodiack</th>\n",
              "      <th>zogranda</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoolog</th>\n",
              "      <th>zophiel</th>\n",
              "      <th>zoroast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.001972</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.012438</td>\n",
              "      <td>0.001972</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.003944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014406</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003204</td>\n",
              "      <td>0.006689</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001659</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.001244</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007051</td>\n",
              "      <td>0.002943</td>\n",
              "      <td>0.002647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017316</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.002381</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>0.003318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.002074</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.002647</td>\n",
              "      <td>0.00083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004954</td>\n",
              "      <td>0.004011</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001639</td>\n",
              "      <td>0.003303</td>\n",
              "      <td>0.000826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008256</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>0.001651</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002674</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows  14740 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        000  00021053  00081429  ...   zoolog   zophiel   zoroast\n",
              "0  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000\n",
              "1  0.000000  0.000000  0.000000  ...  0.00000  0.000000  0.000000\n",
              "2  0.008295  0.000000  0.000000  ...  0.00083  0.000000  0.000415\n",
              "3  0.000000  0.001047  0.001047  ...  0.00000  0.001047  0.000000\n",
              "\n",
              "[4 rows x 14740 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic2D6XgKh2EL"
      },
      "source": [
        "# Is Hamlet more of a Melville or a Milton?\n",
        "shake_hamlet, shake_macbeth, melville, milton = tfidf_bow.squeeze()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TquhGH0-j3ek",
        "outputId": "0f66f059-b75f-428e-cf4d-3d3650a07ca5"
      },
      "source": [
        "# Cosine Similarity\n",
        "# Shakespeare - Shakespeare close\n",
        "# Barely, Hamlet is more Milton (highest similarity) \n",
        "# Big Drop in Cosine Similarity -> why?\n",
        "ham_to_macbeth  = 1 - cosine(shake_hamlet, shake_macbeth)\n",
        "ham_to_melville = 1 - cosine(shake_hamlet, melville)\n",
        "ham_to_milton   = 1 - cosine(shake_hamlet, milton)\n",
        "print(ham_to_macbeth, ham_to_melville, ham_to_milton)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5118436409090338 0.24973387569406813 0.3057994670668329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My0RV1a4vLGW"
      },
      "source": [
        "# Notes on BM25\n",
        "* A long document, would likely have a more diverse set of words compared to a short document\n",
        "  * Would it be surprising to see \"regression\" in a document of length 1,000,000?\n",
        "  * If the word regression appeared in a document of length 1,000 three times, it seems much more important.\n",
        "* BM25 Adjusts TF-IDF for document length\n",
        "* Not implemented in Sklearn, but easy to find implementations"
      ]
    }
  ]
}